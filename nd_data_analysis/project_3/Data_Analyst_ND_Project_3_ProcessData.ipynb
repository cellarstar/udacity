{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Map Analysis\n",
    "### Course: Data Wrangling with MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content: Processing of OSM Dataset\n",
    "- Audit OSM XML\n",
    "- Clean Data\n",
    "- Convert XML Data to JSON Format\n",
    "- Store Data in mongoDB\n",
    "- Investigate Data in mongoDB\n",
    "\n",
    "\n",
    "Note: The Report about this project is stored in a separated file (Data_Analyst_ND_Project_3_ProjectReport.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process OSM Dataset\n",
    "\n",
    "Thoroughly audit and clean your dataset, converting it from XML to JSON format. It is recommended that you start with the Lesson 6 exercises and modify them to suit your chosen data set. As you unravel the data, take note of problems encountered along the way as well as issues with the dataset. You are going to need these when you write your project report. Finally, import the clean JSON file into a MongoDB database and run some queries against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include all the Libaries which will be used later on in Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import xmltodict\n",
    "import json\n",
    "import itertools\n",
    "import pymongo\n",
    "import os\n",
    "import operator\n",
    "import string\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set filename of file being analysed. File is located in the folder of this iPython project / Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'waukesha_county.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some regular expression patterns which will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# patterns to find different types of tags\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# street name pattern to find abbreviations\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# post code pattern\n",
    "post_code_re = re.compile(r'53[0-5][0-9][0-9]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up variable for later usage during data analysis and cleaning. This includes the mapping information for street names as well as a list of all post codes for Waukesha County which is the subject for investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tag categories\n",
    "keys_tag = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "\n",
    "# Mapping of shortcuts for cleaning of street name values\n",
    "city_name_correction_mapping = { \n",
    "    \"MILWAUKEE\" : \"Milwaukee\",    \n",
    "    \"MIlwaukee\" : \"Milwaukee\", \n",
    "    \"milwaukee\" : \"Milwaukee\",\n",
    "    \"Waukesa\"   : \"Waukesha\", \n",
    "    \"waukesha\"   : \"Waukesha\"}\n",
    "\n",
    "# Address/Street \n",
    "street_name_expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "                        \"Trail\", \"Parkway\", \"Commons\", \"Highway\", \"Way\"]\n",
    "\n",
    "# Mapping of shortcuts for cleaning of street name values\n",
    "street_name_mapping = {              \"St\"      : \"Street\",    \"St.\"     : \"Street\",     \"Rd\"      : \"Road\",     \n",
    "            \"Rd.\"     : \"Road\",      \"Ave\"     : \"Avenue\",    \"Ave.\"    : \"Avenue\",     \"Bulvard\" : \"Boulevard\",  \n",
    "            \"Blvd.\"   : \"Boulevard\", \"Blvd\"    : \"Boulevard\", \"Dr\"      : \"Drive\",      \"Dr.\"     : \"Drive\",      \n",
    "            \"Ct\"      : \"Court\",     \"Ct.\"     : \"Court\",     \"Crt\"     : \"Court\",      \"Crt.\"    : \"Court\",  \n",
    "            \"Pl.\"     : \"Place\",     \"PL\"      : \"Place\",     \"Cir\"     : \"Circus\",     \"Tr.\"     : \"Track\",\n",
    "            \"Plc\"     : \"Place\",     \"Plc.\"    : \"Place\",     \"Sqr\"     : \"Square\",     \"Sqr.\"    : \"Square\",     \n",
    "            \"Squ\"     : \"Square\",    \"Squ.\"    : \"Square\",    \"Sq\"      : \"Square\",     \"Sq.\"     : \"Square\",     \n",
    "            \"Ln\"      : \"Lane\",      \"Ln.\"     : \"Lane\",      \"Trl\"     : \"Trail\",      \"Trl.\"    : \"Trail\",      \n",
    "            \"Pky\"     : \"Parkway\",   \"Pky.\"    : \"Parkway\",   \"Pkwy\"    : \"Parkway\",    \"Pkwy.\"   : \"Parkway\",    \n",
    "            \"Hwy\"     : \"Highway\",   \"Hwy.\"    : \"Highway\",   \"R.\"      : \"Road\",       \"W.\"      : \"Way\",\n",
    "            \"Wy.\"     : \"Way\",       \"Wy\"      : \"Way\",       \"Comm.\"   : \"Commons\",    \"Cms.\"    : \"Commons\",\n",
    "            \"N\"       : \"North\",     \"E\"       : \"East\",      \"S\"       : \"South\",      \"W\"       : \"West\"\n",
    "            }\n",
    "\n",
    "# Expteced post codes in Waukesha County - list is retrieved from: \n",
    "# http://www.ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?ClientCode=capitolimpact&State=wi&StName=wisconsin&StFIPS=&FIPS=55133\n",
    "post_code_expected = [\"53005\", \"53007\", \"53008\", \"53018\", \"53029\", \"53045\", \"53046\", \"53051\", \"53052\", \"53056\", \"53058\",\n",
    "                      \"53064\", \"53066\", \"53069\", \"53072\", \"53089\", \"53103\", \"53118\", \"53119\", \"53122\", \"53127\", \"53146\", \n",
    "                      \"53149\", \"53150\", \"53151\", \"53153\", \"53183\", \"53186\", \"53187\", \"53188\", \"53189\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Different Tags in the Data \n",
    "# is retrieving all different kinds of tags used within the data. A very basic function to get some informatio about the data.\n",
    "# INPUT: filename - name of XML file\n",
    "# RETURN: data - dict with different tags and related occurence in the data\n",
    "def count_tags(filename):\n",
    "    # dict for tags\n",
    "    data = dict()\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in data.keys():\n",
    "            noo = data[elem.tag]\n",
    "            data.update({elem.tag:noo+1})\n",
    "        else:\n",
    "            data.update({elem.tag:1})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Different Types of Tags in the Data\n",
    "# Different types are defined by certain regex definitions earlier in the file\n",
    "# INPUT: element - element in XML data\n",
    "# INPUT: keys - dict to store the occurence of specific types\n",
    "# RETURN: keys\n",
    "def key_type(element, keys):\n",
    "    for attributes in element.findall(\"tag\"):\n",
    "        nameK = attributes.get(\"k\")\n",
    "        if lower.match(nameK):\n",
    "            keys[\"lower\"] = keys[\"lower\"]+1\n",
    "        elif lower_colon.match(nameK):\n",
    "            keys[\"lower_colon\"] = keys[\"lower_colon\"]+1\n",
    "        elif problemchars.match(nameK):\n",
    "            keys[\"problemchars\"] = keys[\"problemchars\"]+1\n",
    "        else:\n",
    "            keys[\"other\"] = keys[\"other\"]+1\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of unique users in the data\n",
    "# INPUT: filename - name of XML file\n",
    "# RETURN: users - dict with user list and number of contributions\n",
    "def unique_users(filename):\n",
    "    users = dict()\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        user = elem.get('user')\n",
    "        if user != None:\n",
    "            if user in users.keys():\n",
    "                noo = users[user]\n",
    "                users.update({user:noo+1})\n",
    "            else:\n",
    "                users.update({user:1})\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# check if a tag is a certain type relevant for specific actions\n",
    "########################################################################\n",
    "\n",
    "# Address data checks\n",
    "##############################################################\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_housenumber(elem):\n",
    "    return (elem.attrib['k'] == \"addr:housenumber\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_post_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_city(elem):\n",
    "    return (elem.attrib['k'] == \"addr:city\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_state(elem):\n",
    "    return (elem.attrib['k'] == \"addr:state\")\n",
    "##############################################################\n",
    "\n",
    "# Generic Info data checks\n",
    "##############################################################\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_name(elem):\n",
    "    return (elem.attrib['k'] == \"name\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_amenity(elem):\n",
    "    return (elem.attrib['k'] == \"amenity\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_opening_hours(elem):\n",
    "    return (elem.attrib['k'] == \"opening_hours\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_phone(elem):\n",
    "    return (elem.attrib['k'] == \"phone\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_website(elem):\n",
    "    return (elem.attrib['k'] == \"website\")\n",
    "\n",
    "# Cusisine data checks\n",
    "##########################################\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_cuisine(elem):\n",
    "    return (elem.attrib['k'] == \"cuisine\")\n",
    "\n",
    "# Relegion Info data checks\n",
    "##########################################\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_denomination(elem):\n",
    "    return (elem.attrib['k'] == \"denomination\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_religion(elem):\n",
    "    return (elem.attrib['k'] == \"religion\")\n",
    "\n",
    "# Shop Info data checks\n",
    "##########################################\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_shop(elem):\n",
    "    return (elem.attrib['k'] == \"shop\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_highway(elem):\n",
    "    return (elem.attrib['k'] == \"highway\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_building(elem):\n",
    "    return (elem.attrib['k'] == \"building\")\n",
    "\n",
    "# INPUT: element - element in XML data\n",
    "# RETURN: boolean - true if tag fits condition \n",
    "def is_type(elem):\n",
    "    return (elem.attrib['k'] == \"type\")\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This creates a set of street names for different types of streets where the name does not fit to the \n",
    "# expected street name pattern. Thus the function helps to identify streetname of bad quality.\n",
    "# INPUT: type_set - set of different streets\n",
    "# INPUT: value - streetname\n",
    "def audit_street_type(type_set, value):\n",
    "    naming = street_type_re.search(value)\n",
    "    if naming:\n",
    "        stype = naming.group()\n",
    "        found = False\n",
    "        for k in street_name_mapping.keys():\n",
    "            if ((k in value) or (street_name_mapping[k] in value) or (stype in street_name_expected)):\n",
    "                found = True\n",
    "        if not found:\n",
    "            type_set[stype].add(value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this creates a set of post codes for different where the post code does not fit to the \n",
    "# expected post code pattern of Waukesha County. Thus the function helps to identify wrong labled\n",
    "# post codes in the data.\n",
    "# INPUT: type_set - set of different streets\n",
    "# INPUT: value - streetname\n",
    "def audit_post_code_types(type_set, value):\n",
    "    if value not in post_code_expected:\n",
    "        if value in type_set.keys():\n",
    "            noo = type_set[value]\n",
    "            type_set[value] = noo+1\n",
    "        else:\n",
    "            type_set[value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# audit amenity type function collects all different types of amenity and their occurences in the data\n",
    "# INPUT: type_set - set of amenities\n",
    "# INPUT: value - amenity\n",
    "def audit_type(type_set, value):\n",
    "    if value in type_set.keys():\n",
    "        noo = type_set[value]\n",
    "        type_set[value] = noo+1\n",
    "    else:\n",
    "        type_set[value] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main function to audit the data\n",
    "# INPUT: osmfile - original XML file from OSM\n",
    "# RETURN: tag_types - dict with different types of tags and occurences\n",
    "# RETURN: street_types  - dict with different streetnames and occurences\n",
    "# RETURN: amenity_types  - dict with different amenities and occurences\n",
    "# RETURN: post_code_types - dict with different post codes and occurences\n",
    "# RETURN: wrong_post_code_types - dict with wrong post codes failing validation and occurences\n",
    "# RETURN: cities_dict - dict with different cities and occurences\n",
    "def audit(osmfile):\n",
    "    \n",
    "    # open file\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    \n",
    "    # container for analysis\n",
    "    street_types= defaultdict(set) # container for unexpected street name occurences\n",
    "    amenity_types = dict() # container for all different types of amenity and related number of occurence\n",
    "    cities_dict = dict() # container for all different cities and related number of occurence\n",
    "    post_code_types = dict() # container for all different types of amenity and related number of occurence\n",
    "    wrong_post_code_types = dict() # container for all different types of wrong post codes and related number of occurence\n",
    "    tag_types = dict() # container for different types of tags and related number of occurence\n",
    "    \n",
    "    # loop data\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        \n",
    "        ##########################################################\n",
    "        # START: Counting tag types\n",
    "        if elem.tag in tag_types.keys():\n",
    "            noo = tag_types[elem.tag]\n",
    "            tag_types.update({elem.tag:(noo+1)})\n",
    "        else:\n",
    "            tag_types.update({elem.tag:1})\n",
    "        # END\n",
    "        ##########################################################\n",
    "        \n",
    "        # looking into node, way and realtions tags only\n",
    "        if elem.tag in (\"node\", \"way\", \"relation\"):\n",
    "            \n",
    "            # iterating through tag elements in node/way\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                \n",
    "                ##########################################################\n",
    "                # START: analysing street name tags\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                # END\n",
    "                ##########################################################\n",
    "                \n",
    "                ##########################################################\n",
    "                # START: analysing amenity tags\n",
    "                if is_amenity(tag):\n",
    "                    audit_type(amenity_types, tag.attrib['v'])\n",
    "                # END\n",
    "                ##########################################################\n",
    "                \n",
    "                ##########################################################\n",
    "                # START: analysing post code tags\n",
    "                if is_post_code(tag):\n",
    "                    # list of all different post codes in the data and their occurence\n",
    "                    audit_type(post_code_types, tag.attrib['v'])\n",
    "                    # audit if all the post codes are related to waukesha county area\n",
    "                    audit_post_code_types(wrong_post_code_types, tag.attrib['v'])\n",
    "                # END\n",
    "                ##########################################################\n",
    "                \n",
    "                ##########################################################\n",
    "                # START: analysing post code tags\n",
    "                if is_city(tag):\n",
    "                    # list of all different post codes in the data and their occurence\n",
    "                    audit_type(cities_dict, tag.attrib['v'])\n",
    "                # END\n",
    "                ##########################################################\n",
    "                    \n",
    "    osm_file.close()\n",
    "    \n",
    "    return tag_types, street_types, amenity_types, post_code_types, wrong_post_code_types, cities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of OSM data file: \n",
      "192404 KB\n"
     ]
    }
   ],
   "source": [
    "# Return the size, in bytes, of path. Raise os.error if the file does not exist or is inaccessible.\n",
    "print \"Size of OSM data file: \"\n",
    "print (str(os.path.getsize(filename)/1024)) + \" KB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Key Types and Number of Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'--------------- Key Types & Count ------------------'\n",
      "'Different Key Types and Number of Occurence:'\n",
      "'----------------------------------------------------'\n",
      "{'lower': 718689, 'lower_colon': 804417, 'other': 35025, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "# analysis of the different keys (k) used inside the tag element\n",
    "for id, element in ET.iterparse(filename):\n",
    "    keys_tag = key_type(element, keys_tag)\n",
    "################################################\n",
    "pprint.pprint(\"--------------- Key Types & Count ------------------\")\n",
    "pprint.pprint(\"Different Key Types and Number of Occurence:\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(keys_tag)\n",
    "\n",
    "# Need to free up variables\n",
    "# in order to get RAM utilization managed#\n",
    "element = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is using regex definition from earlier in this file. What's of most interest here is, that no tags with problematic characters are in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'--------------- Users ------------------'\n",
      "'Number of unique users: 682'\n",
      "'----------------------------------------'\n",
      "'Top 10 users in the list and the number'\n",
      "'of posts:'\n",
      "'----------------------------------------'\n",
      "('woodpeck_fixbot', 217089)\n",
      "('ItalianMustache', 102449)\n",
      "('shuui', 94917)\n",
      "('hogrod', 48592)\n",
      "('reschultzed', 40931)\n",
      "('bbauter', 29704)\n",
      "('Mulad', 28162)\n",
      "('Gary Cox', 27193)\n",
      "('iandees', 26923)\n",
      "('TIGERcnl', 25893)\n"
     ]
    }
   ],
   "source": [
    "# list of unique users contributing to osm data\n",
    "users = unique_users(filename)\n",
    "################################################\n",
    "pprint.pprint(\"--------------- Users ------------------\")\n",
    "pprint.pprint(\"Number of unique users: \" + str(len(users)))\n",
    "pprint.pprint(\"----------------------------------------\") \n",
    "pprint.pprint(\"Top 10 users in the list and the number\")\n",
    "pprint.pprint(\"of posts:\")\n",
    "pprint.pprint(\"----------------------------------------\") \n",
    "for i in range(0, 10):\n",
    "    pprint.pprint(sorted(users.items(), key=operator.itemgetter(1), reverse=True)[i])\n",
    "\n",
    "# Need to free up variables\n",
    "# in order to get RAM utilization managed\n",
    "users = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Various Insights and Numbers related to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling audit function to collect auditing information about the data\n",
    "tag_types, street_types, amenity_types, post_code_types, wrong_post_code_types, cities_dict = audit(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'------------------- Tag Types ----------------------'\n",
      "'Below is a list of different Tags and and their'\n",
      "'occurence in the data.'\n",
      "'----------------------------------------------------'\n",
      "[('nd', 1052051),\n",
      " ('node', 860835),\n",
      " ('tag', 519377),\n",
      " ('way', 92239),\n",
      " ('member', 17750),\n",
      " ('relation', 786),\n",
      " ('note', 1),\n",
      " ('meta', 1),\n",
      " ('bounds', 1),\n",
      " ('osm', 1)]\n",
      "'----------------------------------------------------'\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"------------------- Tag Types ----------------------\")\n",
    "pprint.pprint(\"Below is a list of different Tags and and their\")\n",
    "pprint.pprint(\"occurence in the data.\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(sorted(tag_types.items(), key=operator.itemgetter(1), reverse=True))\n",
    "pprint.pprint(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'------------------ Street Types --------------------'\n",
      "'Below street names are those which do not fit into '\n",
      "'street names or street names abbrivations which are'\n",
      "'defined earlier in street_name_mapping variable.'\n",
      "'----------------------------------------------------'\n",
      "'53076:'\n",
      "set(['53076'])\n",
      "'-------------------------------'\n",
      "u'napaonline.com\\u200e:'\n",
      "set([u'napaonline.com\\u200e'])\n",
      "'-------------------------------'\n",
      "'Pointe:'\n",
      "set(['Gaslight Pointe'])\n",
      "'-------------------------------'\n",
      "'----------------------------------------------------'\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"------------------ Street Types --------------------\")\n",
    "pprint.pprint(\"Below street names are those which do not fit into \")\n",
    "pprint.pprint(\"street names or street names abbrivations which are\")\n",
    "pprint.pprint(\"defined earlier in street_name_mapping variable.\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "for st_t in street_types:\n",
    "    pprint.pprint(st_t + \":\")\n",
    "    pprint.pprint(street_types[st_t])\n",
    "    pprint.pprint(\"-------------------------------\")\n",
    "pprint.pprint(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'------------------ Amenity Types -------------------'\n",
      "'Below is a list of different amenities and and their'\n",
      "'occurence in the data.'\n",
      "'----------------------------------------------------'\n",
      "('parking', 2305)\n",
      "('school', 997)\n",
      "('parking_entrance', 569)\n",
      "('restaurant', 444)\n",
      "('fast_food', 230)\n",
      "('grave_yard', 199)\n",
      "('fuel', 192)\n",
      "('place_of_worship', 171)\n",
      "('bench', 142)\n",
      "('bank', 110)\n",
      "'----------------------------------------------------'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"------------------ Amenity Types -------------------\")\n",
    "pprint.pprint(\"Below is a list of different amenities and and their\")\n",
    "pprint.pprint(\"occurence in the data.\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "for i in range(0, 10):\n",
    "    pprint.pprint(sorted(amenity_types.items(), key=operator.itemgetter(1), reverse=True)[i])\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'----------------- Post Codes ------------------'\n",
      "'Below is a list of all post codes and and their'\n",
      "'occurence in the data.'\n",
      "'----------------------------------------------------'\n",
      "'Number of different Post Codes: 98'\n",
      "'----------------------------------------------------'\n",
      "('53202', 993)\n",
      "('53212', 255)\n",
      "('53203', 229)\n",
      "('53538', 143)\n",
      "('53233', 132)\n",
      "('53211', 93)\n",
      "('53204', 67)\n",
      "('53215', 47)\n",
      "('53094', 42)\n",
      "('53027', 38)\n",
      "'----------------------------------------------------'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"----------------- Post Codes ------------------\")\n",
    "pprint.pprint(\"Below is a list of all post codes and and their\")\n",
    "pprint.pprint(\"occurence in the data.\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(\"Number of different Post Codes: \" + str(len(post_code_types)))\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "for i in range(0, 10):\n",
    "    pprint.pprint(sorted(post_code_types.items(), key=operator.itemgetter(1), reverse=True)[i])\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'--------------- Correct Post Codes -----------------'\n",
      "'Below is a list of post codes which do belong to'\n",
      "'Waukesha County and their occurence in the data.'\n",
      "'----------------------------------------------------'\n",
      "'Number of different Correct Post Codes: 22'\n",
      "'----------------------------------------------------'\n",
      "('53029', 23)\n",
      "('53186', 23)\n",
      "('53066', 12)\n",
      "('53072', 11)\n",
      "('53045', 11)\n",
      "('53051', 10)\n",
      "('53005', 9)\n",
      "('53188', 8)\n",
      "('53151', 7)\n",
      "('53146', 3)\n",
      "('53149', 3)\n",
      "('53069', 3)\n",
      "('53089', 2)\n",
      "('53150', 2)\n",
      "('53122', 2)\n",
      "('53189', 2)\n",
      "('53153', 1)\n",
      "('53007', 1)\n",
      "('53018', 1)\n",
      "('53183', 1)\n",
      "('53187', 1)\n",
      "('53103', 1)\n",
      "'----------------------------------------------------'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"--------------- Correct Post Codes -----------------\")\n",
    "pprint.pprint(\"Below is a list of post codes which do belong to\")\n",
    "pprint.pprint(\"Waukesha County and their occurence in the data.\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "sorted_post_codes = sorted(post_code_types.items(), key=operator.itemgetter(1), reverse=True)\n",
    "pprint.pprint(\"Number of different Correct Post Codes: \" + str((len(sorted_post_codes)-(len(wrong_post_code_types)))))\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "for post_code in sorted_post_codes:\n",
    "    if post_code[0] not in wrong_post_code_types.keys():\n",
    "        print post_code\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'----------------- Wrong Post Codes -------------------'\n",
      "'Below is a list of post codes which do not belong to'\n",
      "'Waukesha County and their occurence in the data.'\n",
      "'------------------------------------------------------'\n",
      "'Number of different Post Codes: 76'\n",
      "'CAUTION: This is a list of the TOP 10 Wrong Post Codes'\n",
      "'------------------------------------------------------'\n",
      "('53202', 993)\n",
      "('53212', 255)\n",
      "('53203', 229)\n",
      "('53538', 143)\n",
      "('53233', 132)\n",
      "('53211', 93)\n",
      "('53204', 67)\n",
      "('53215', 47)\n",
      "('53094', 42)\n",
      "('53027', 38)\n",
      "'------------------------------------------------------'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"----------------- Wrong Post Codes -------------------\")\n",
    "pprint.pprint(\"Below is a list of post codes which do not belong to\")\n",
    "pprint.pprint(\"Waukesha County and their occurence in the data.\")\n",
    "pprint.pprint(\"------------------------------------------------------\")\n",
    "pprint.pprint(\"Number of different Post Codes: \" + str(len(wrong_post_code_types)))\n",
    "pprint.pprint('CAUTION: This is a list of the TOP 10 Wrong Post Codes')\n",
    "pprint.pprint(\"------------------------------------------------------\")\n",
    "for i in range(0, 10):\n",
    "    pprint.pprint(sorted(wrong_post_code_types.items(), key=operator.itemgetter(1), reverse=True)[i])\n",
    "pprint.pprint(\"------------------------------------------------------\")\n",
    "pprint.pprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'---------------- Wrong Post Codes ------------------'\n",
      "'Below is a list of post codes which do not match an'\n",
      "'extended pattern around Waukesha County and their'\n",
      "'occurence in the data.'\n",
      "'Pattern: (1) 53000 - 53599 and'\n",
      "'         (2) length of post code is 5 chars'\n",
      "'----------------------------------------------------'\n",
      "'53403-9998'\n",
      "'Milwaukee WI, 53222'\n",
      "'54220'\n",
      "'WI'\n",
      "'53214-3110'\n",
      "'53203-3099'\n",
      "'1729'\n",
      "'53217-5399'\n",
      "'----------------------------------------------------'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"---------------- Wrong Post Codes ------------------\")\n",
    "pprint.pprint(\"Below is a list of post codes which do not match an\")\n",
    "pprint.pprint(\"extended pattern around Waukesha County and their\")\n",
    "pprint.pprint(\"occurence in the data.\")\n",
    "pprint.pprint(\"Pattern: (1) 53000 - 53599 and\")\n",
    "pprint.pprint(\"         (2) length of post code is 5 chars\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "for post_code in wrong_post_code_types:\n",
    "    # check agains regex for valid post codes\n",
    "    is_valid_post_code = post_code_re.match(post_code)\n",
    "    # if post code does not match expected pattern or post code length is not 5\n",
    "    if (not is_valid_post_code) or (len(post_code) != 5):\n",
    "        pprint.pprint(post_code)\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'---------------- Different Cities ------------------'\n",
      "'Below is a list of different cities mentioned in the'\n",
      "'data and their occurence.'\n",
      "'----------------------------------------------------'\n",
      "('Milwaukee', 1592)\n",
      "('Racine', 561)\n",
      "('Fort Atkinson', 145)\n",
      "('Mount Pleasant', 120)\n",
      "('Waterloo', 57)\n",
      "('Watertown', 46)\n",
      "('Waukesha', 31)\n",
      "('Caledonia', 29)\n",
      "('Sturtevant', 27)\n",
      "('MIlwaukee', 23)\n",
      "'----------------------------------------------------'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(\"---------------- Different Cities ------------------\")\n",
    "pprint.pprint(\"Below is a list of different cities mentioned in the\")\n",
    "pprint.pprint(\"data and their occurence.\")\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "for i in range(0, 10):\n",
    "    pprint.pprint(sorted(cities_dict.items(), key=operator.itemgetter(1), reverse=True)[i])\n",
    "pprint.pprint(\"----------------------------------------------------\")\n",
    "pprint.pprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to free up variables\n",
    "# in order to get RAM utilization managed\n",
    "tag_types = {}\n",
    "street_types = {}\n",
    "amenity_types = {}\n",
    "post_code_types = {}\n",
    "wrong_post_code_types = {}\n",
    "cities_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of restaurant in Set():\n",
      "993\n",
      "Number of iterations in \"school\" condition:\n",
      "993\n",
      "List all school id's:\n",
      "392886197\n",
      "392886196\n",
      "1938373853\n",
      "180987114\n",
      "395662863\n",
      "1157330189\n",
      "184082104\n",
      "369923548\n",
      "184082102\n",
      "392886199\n",
      "183095129\n",
      "53216812\n",
      "394657139\n",
      "53216818\n",
      "3913173676\n",
      "117040603\n",
      "3882343685\n",
      "51865486\n",
      "827596583\n",
      "68798474\n",
      "5937219\n",
      "90547171\n",
      "183340708\n",
      "53160857\n",
      "298358438\n",
      "53160858\n",
      "3969864878\n",
      "393262123\n",
      "393262126\n",
      "395178071\n",
      "180987111\n",
      "55262352\n",
      "392886198\n",
      "51865535\n",
      "53216288\n",
      "116895728\n",
      "3983518158\n",
      "3960987399\n",
      "115013002\n",
      "53160488\n",
      "53160561\n",
      "3969864882\n",
      "93829843\n",
      "3969864880\n",
      "93829846\n",
      "395662860\n",
      "395662861\n",
      "183171727\n",
      "53160357\n",
      "395662864\n",
      "184082092\n",
      "395662868\n",
      "3986531514\n",
      "183249500\n",
      "183171728\n",
      "3986531513\n",
      "107937238\n",
      "255437342\n",
      "53160687\n",
      "393233755\n",
      "53160682\n",
      "191237612\n",
      "392848483\n",
      "392848482\n",
      "392848481\n",
      "394657136\n",
      "395889444\n",
      "3971992781\n",
      "394706133\n",
      "394706131\n",
      "394706136\n",
      "394706138\n",
      "394706139\n",
      "381257038\n",
      "181033244\n",
      "181033247\n",
      "394686801\n",
      "3993030972\n",
      "384574237\n",
      "1318516485\n",
      "1050724370\n",
      "383142389\n",
      "2611216473\n",
      "394227005\n",
      "101476839\n",
      "393233753\n",
      "3985506873\n",
      "396092145\n",
      "394409366\n",
      "3995771168\n",
      "2836259488\n",
      "69020495\n",
      "1050559925\n",
      "400100819\n",
      "53216147\n",
      "3985443352\n",
      "3985443353\n",
      "3985443350\n",
      "3985443351\n",
      "3985537583\n",
      "3985537582\n",
      "3985443354\n",
      "3985443355\n",
      "68581078\n",
      "334854361\n",
      "51865503\n",
      "394686820\n",
      "51865506\n",
      "51865504\n",
      "1301132785\n",
      "116895726\n",
      "51865508\n",
      "51865509\n",
      "3967523946\n",
      "3967523947\n",
      "3882343537\n",
      "3882343530\n",
      "392895965\n",
      "395856705\n",
      "185565699\n",
      "68998546\n",
      "3882343539\n",
      "3882343538\n",
      "183384778\n",
      "221203251\n",
      "394657141\n",
      "93824148\n",
      "3976858202\n",
      "3976858203\n",
      "3976858200\n",
      "183340704\n",
      "183340707\n",
      "183340701\n",
      "93824146\n",
      "1050560010\n",
      "393075943\n",
      "3974852168\n",
      "27373046\n",
      "27373044\n",
      "3974852163\n",
      "183801791\n",
      "69020402\n",
      "68580831\n",
      "3965020664\n",
      "3965020662\n",
      "3965020661\n",
      "3965020660\n",
      "116896205\n",
      "392821852\n",
      "3988926188\n",
      "69020390\n",
      "1043706994\n",
      "1249440712\n",
      "391512074\n",
      "396746938\n",
      "396746937\n",
      "53216718\n",
      "183802017\n",
      "1312423927\n",
      "393729938\n",
      "395703566\n",
      "3964515888\n",
      "5932448\n",
      "182486089\n",
      "3964515887\n",
      "3985368923\n",
      "393272939\n",
      "3987063686\n",
      "3987063687\n",
      "3985368927\n",
      "3993030974\n",
      "3985368925\n",
      "3985368924\n",
      "3985368929\n",
      "3985368928\n",
      "384879595\n",
      "53216562\n",
      "395178073\n",
      "383142393\n",
      "53160801\n",
      "3986944487\n",
      "395703568\n",
      "169914794\n",
      "384879596\n",
      "384879598\n",
      "384879599\n",
      "255676078\n",
      "3986944488\n",
      "3981178957\n",
      "200354726\n",
      "397906913\n",
      "1249395851\n",
      "255676322\n",
      "256669851\n",
      "3981178959\n",
      "3981178958\n",
      "247919055\n",
      "103512501\n",
      "395910175\n",
      "4030249360\n",
      "101476843\n",
      "395662850\n",
      "292996913\n",
      "3964575915\n",
      "395662857\n",
      "3964575916\n",
      "395889443\n",
      "394706143\n",
      "395889442\n",
      "185566051\n",
      "185566050\n",
      "395889440\n",
      "3964855268\n",
      "3964855269\n",
      "3964855267\n",
      "184082098\n",
      "4030674506\n",
      "183802018\n",
      "401851754\n",
      "3985537707\n",
      "68962993\n",
      "3995710552\n",
      "393271474\n",
      "3995710550\n",
      "3995710551\n",
      "114919323\n",
      "2611216471\n",
      "395856711\n",
      "223137608\n",
      "394227008\n",
      "114919326\n",
      "3972367261\n",
      "3972367260\n",
      "394227004\n",
      "393271477\n",
      "376170018\n",
      "394227007\n",
      "3950762888\n",
      "184082097\n",
      "395178077\n",
      "394227003\n",
      "3962123628\n",
      "1318506223\n",
      "255677033\n",
      "1318506228\n",
      "1318506229\n",
      "313319223\n",
      "181960472\n",
      "3962123626\n",
      "3962123627\n",
      "183802013\n",
      "107937231\n",
      "393729890\n",
      "53217211\n",
      "107937232\n",
      "69282155\n",
      "4030597719\n",
      "107937237\n",
      "107937236\n",
      "3976537661\n",
      "3976537662\n",
      "3976537663\n",
      "3976537664\n",
      "53160747\n",
      "53160989\n",
      "394686793\n",
      "1239454024\n",
      "34516\n",
      "394686797\n",
      "1239454027\n",
      "1239454028\n",
      "3796240954\n",
      "185565715\n",
      "185565714\n",
      "185565713\n",
      "53160986\n",
      "114917232\n",
      "393273767\n",
      "393273766\n",
      "3966671171\n",
      "3966671172\n",
      "69020680\n",
      "185565707\n",
      "672758188\n",
      "3960817687\n",
      "3960817685\n",
      "3882343548\n",
      "3882343549\n",
      "1050724533\n",
      "3882343544\n",
      "3882343545\n",
      "3882343546\n",
      "3882343547\n",
      "3882343540\n",
      "3882343541\n",
      "3882343542\n",
      "3882343543\n",
      "3960331315\n",
      "3960331314\n",
      "3960331312\n",
      "392821855\n",
      "185565708\n",
      "181033038\n",
      "392821851\n",
      "393497242\n",
      "392821853\n",
      "53160611\n",
      "183340699\n",
      "4026950155\n",
      "180905176\n",
      "4039188836\n",
      "1239454283\n",
      "3960817673\n",
      "3960817671\n",
      "3960817670\n",
      "3960817677\n",
      "3976287818\n",
      "3960817675\n",
      "3960817674\n",
      "3968909181\n",
      "369925845\n",
      "3965020658\n",
      "3965020659\n",
      "3965020657\n",
      "117040598\n",
      "117040599\n",
      "221203254\n",
      "183472205\n",
      "394686789\n",
      "79627957\n",
      "396098183\n",
      "53161163\n",
      "255675707\n",
      "393475872\n",
      "393475871\n",
      "3968909184\n",
      "53160272\n",
      "183097241\n",
      "396098181\n",
      "394706144\n",
      "3982187487\n",
      "396744730\n",
      "396744732\n",
      "101463593\n",
      "53160577\n",
      "183095130\n",
      "94667005\n",
      "3971822844\n",
      "183249002\n",
      "93829836\n",
      "93829837\n",
      "394226995\n",
      "395662862\n",
      "69020761\n",
      "183171726\n",
      "34901930\n",
      "3993030982\n",
      "3993030983\n",
      "292997220\n",
      "395889446\n",
      "395662865\n",
      "53160938\n",
      "1312416042\n",
      "183384779\n",
      "1112231470\n",
      "3449164421\n",
      "396092144\n",
      "3842929817\n",
      "94666997\n",
      "94666996\n",
      "94666995\n",
      "94666999\n",
      "395714612\n",
      "3842929819\n",
      "395906398\n",
      "673566282\n",
      "396489489\n",
      "383142390\n",
      "117035310\n",
      "383142392\n",
      "1043417874\n",
      "393024608\n",
      "395906397\n",
      "117035311\n",
      "190295317\n",
      "1295751517\n",
      "395893990\n",
      "395207781\n",
      "4030249356\n",
      "1043416655\n",
      "4030249351\n",
      "183384786\n",
      "183384781\n",
      "183384780\n",
      "183384783\n",
      "397906911\n",
      "2623053728\n",
      "169915044\n",
      "4027255902\n",
      "4027255901\n",
      "94667002\n",
      "53160620\n",
      "53216155\n",
      "69020763\n",
      "1089861665\n",
      "3965019756\n",
      "3965019755\n",
      "3965019754\n",
      "3965019753\n",
      "3965019752\n",
      "3965019750\n",
      "3985443349\n",
      "169913463\n",
      "69020648\n",
      "395207786\n",
      "183384777\n",
      "398772666\n",
      "395165346\n",
      "51865511\n",
      "3972367258\n",
      "3972367259\n",
      "183248584\n",
      "221203259\n",
      "395714613\n",
      "169914242\n",
      "396618516\n",
      "2046706220\n",
      "396618514\n",
      "393729924\n",
      "1090282421\n",
      "170013656\n",
      "180905180\n",
      "3983443932\n",
      "3983443933\n",
      "395645016\n",
      "395645017\n",
      "3974550577\n",
      "395645015\n",
      "183340716\n",
      "183340717\n",
      "395645019\n",
      "183340713\n",
      "183340710\n",
      "53160659\n",
      "395703565\n",
      "183802016\n",
      "170010754\n",
      "170010755\n",
      "90547166\n",
      "170010757\n",
      "170010758\n",
      "115010395\n",
      "191237614\n",
      "191237613\n",
      "53256259\n",
      "191237611\n",
      "395165348\n",
      "1318506241\n",
      "53237053\n",
      "393271473\n",
      "3965019746\n",
      "393271480\n",
      "381278418\n",
      "393271482\n",
      "393271483\n",
      "393271475\n",
      "53160530\n",
      "53160532\n",
      "255436840\n",
      "393729909\n",
      "180629408\n",
      "1618890\n",
      "396489494\n",
      "396489493\n",
      "396489492\n",
      "396489491\n",
      "395178078\n",
      "2474169\n",
      "265848059\n",
      "395856710\n",
      "393271476\n",
      "55205380\n",
      "393271485\n",
      "3974682469\n",
      "183802015\n",
      "402307023\n",
      "394227009\n",
      "90547165\n",
      "53216572\n",
      "3951887863\n",
      "3951887862\n",
      "3951887861\n",
      "53160871\n",
      "4030885974\n",
      "4030885975\n",
      "394706141\n",
      "394706140\n",
      "4030885970\n",
      "3966868940\n",
      "4030885973\n",
      "3981178960\n",
      "3981178961\n",
      "3981178962\n",
      "3981178963\n",
      "3981178964\n",
      "3981178965\n",
      "3981178966\n",
      "3981178967\n",
      "393497241\n",
      "53160543\n",
      "53160544\n",
      "190471104\n",
      "395906402\n",
      "393546780\n",
      "383142391\n",
      "395178074\n",
      "393936417\n",
      "182486307\n",
      "395178076\n",
      "66796162\n",
      "185566049\n",
      "4029404584\n",
      "4029404585\n",
      "4029404582\n",
      "4029404583\n",
      "381278420\n",
      "170014244\n",
      "170014245\n",
      "183802010\n",
      "3964855275\n",
      "3964855274\n",
      "3964855271\n",
      "3964855273\n",
      "3964855272\n",
      "292997700\n",
      "400370008\n",
      "186241256\n",
      "186241255\n",
      "53160315\n",
      "2611238832\n",
      "190846345\n",
      "190846342\n",
      "396098182\n",
      "395856704\n",
      "53161064\n",
      "395856706\n",
      "3960168011\n",
      "183802011\n",
      "394149271\n",
      "2862464666\n",
      "400634077\n",
      "393120516\n",
      "395856708\n",
      "395856709\n",
      "395178064\n",
      "1318506235\n",
      "53161067\n",
      "68581036\n",
      "53256255\n",
      "90547162\n",
      "181960475\n",
      "181960474\n",
      "181960477\n",
      "181960476\n",
      "101476850\n",
      "3979968245\n",
      "3979968244\n",
      "53160860\n",
      "395703563\n",
      "395703562\n",
      "3966671169\n",
      "185565703\n",
      "185565704\n",
      "1316823191\n",
      "66719111\n",
      "3327388274\n",
      "3966671163\n",
      "185565709\n",
      "3968909183\n",
      "3968909182\n",
      "3966671167\n",
      "3966671166\n",
      "3966671165\n",
      "3966671164\n",
      "183248643\n",
      "93835239\n",
      "93835238\n",
      "394686809\n",
      "116899517\n",
      "395893998\n",
      "51865524\n",
      "393729895\n",
      "394686807\n",
      "93835237\n",
      "51865521\n",
      "51865522\n",
      "107937234\n",
      "2611237176\n",
      "3882343550\n",
      "393237788\n",
      "3882343556\n",
      "395906404\n",
      "395906406\n",
      "395906401\n",
      "395906403\n",
      "1249455070\n",
      "53237361\n",
      "367808530\n",
      "1318506246\n",
      "395703569\n",
      "3976744977\n",
      "3976744978\n",
      "3976744979\n",
      "1318506249\n",
      "255676288\n",
      "393262114\n",
      "393729919\n",
      "393262115\n",
      "190471106\n",
      "183920553\n",
      "169914421\n",
      "190471105\n",
      "3979968252\n",
      "255675922\n",
      "391815079\n",
      "393262113\n",
      "183920552\n",
      "53237058\n",
      "183920554\n",
      "3962796396\n",
      "183920557\n",
      "183920558\n",
      "255676312\n",
      "395893994\n",
      "43868232\n",
      "395662852\n",
      "1076165565\n",
      "3843048103\n",
      "3986895671\n",
      "3986895670\n",
      "55206404\n",
      "394686784\n",
      "6035541\n",
      "3964712482\n",
      "3964712483\n",
      "183472211\n",
      "183472210\n",
      "384909622\n",
      "400333223\n",
      "186840251\n",
      "190295329\n",
      "186840256\n",
      "190295322\n",
      "190295323\n",
      "190295320\n",
      "53160666\n",
      "190295327\n",
      "190295324\n",
      "190295325\n",
      "3984698246\n",
      "53160668\n",
      "183340693\n",
      "66709384\n",
      "3957447036\n",
      "3957447035\n",
      "53160942\n",
      "3963332784\n",
      "3963332787\n",
      "3963332780\n",
      "185565711\n",
      "3963332782\n",
      "3963332783\n",
      "53160829\n",
      "53160828\n",
      "3963332788\n",
      "3286451977\n",
      "391805177\n",
      "109026449\n",
      "109026448\n",
      "396488001\n",
      "3962796299\n",
      "3962796298\n",
      "3965020741\n",
      "3985444570\n",
      "3863547920\n",
      "1096708063\n",
      "183463883\n",
      "3980794696\n",
      "255675920\n",
      "393273761\n",
      "255675921\n",
      "190295328\n",
      "3985537584\n",
      "169914613\n",
      "394657140\n",
      "69020655\n",
      "3985537581\n",
      "53160893\n",
      "395662871\n",
      "53160328\n",
      "190295321\n",
      "6022487\n",
      "3985368926\n",
      "3049739921\n",
      "68581214\n",
      "395645021\n",
      "395645020\n",
      "182486080\n",
      "182486081\n",
      "182486083\n",
      "393277041\n",
      "395856707\n",
      "395889441\n",
      "53256244\n",
      "53256242\n",
      "1239454008\n",
      "183802019\n",
      "3964475116\n",
      "3964475117\n",
      "183802014\n",
      "3964475115\n",
      "183802012\n",
      "1239454003\n",
      "53160645\n",
      "53256248\n",
      "116523169\n",
      "393497240\n",
      "393287835\n",
      "68744737\n",
      "3966671159\n",
      "393497244\n",
      "393497245\n",
      "183095135\n",
      "183095134\n",
      "183095137\n",
      "183095136\n",
      "183095131\n",
      "1077834445\n",
      "183095133\n",
      "183095132\n",
      "392886200\n",
      "1171649836\n",
      "393729915\n",
      "296366269\n",
      "393024609\n",
      "255436839\n",
      "255436838\n",
      "402585480\n",
      "255436837\n",
      "386868370\n",
      "393024607\n",
      "109031942\n",
      "68649538\n",
      "69020632\n",
      "396489490\n",
      "394459306\n",
      "51865499\n",
      "93835240\n",
      "4030885968\n",
      "4030885963\n",
      "53160866\n",
      "90547164\n",
      "4030885960\n",
      "4030885967\n",
      "4030885966\n",
      "4030885965\n",
      "4030885964\n",
      "5893521\n",
      "169913705\n",
      "53216745\n",
      "3981178978\n",
      "3981178977\n",
      "3981178976\n",
      "3981178975\n",
      "3981178974\n",
      "3981178973\n",
      "3981178972\n",
      "3981178971\n",
      "3981178970\n",
      "2413932352\n",
      "5913128\n",
      "1328513190\n",
      "3980794694\n",
      "256669204\n",
      "395662873\n",
      "395662872\n",
      "256669201\n",
      "395662870\n",
      "394686812\n",
      "169915035\n",
      "190295331\n",
      "1249455083\n",
      "3971880806\n",
      "3971880807\n",
      "3971880805\n",
      "53160916\n",
      "68762980\n",
      "298636534\n",
      "185565710\n",
      "116904460\n",
      "394227011\n",
      "396996308\n",
      "3248418440\n",
      "68962603\n",
      "3960913234\n",
      "395485685\n",
      "3992448344\n",
      "3992448345\n",
      "3992448346\n",
      "3992448347\n",
      "3992448341\n",
      "3863547918\n",
      "3863547919\n",
      "3863547916\n",
      "3863547917\n",
      "3863547914\n",
      "3863547915\n",
      "3863547912\n",
      "3863547913\n",
      "117043704\n",
      "1934596062\n",
      "180595016\n",
      "95915212\n",
      "116896196\n",
      "116896197\n",
      "101476841\n",
      "101476842\n",
      "53160824\n",
      "101476844\n",
      "101476845\n",
      "101476846\n",
      "255675709\n",
      "393272944\n",
      "393272945\n",
      "183340695\n",
      "393272943\n",
      "1050560044\n",
      "169914548\n",
      "3971822854\n",
      "394657135\n",
      "53160604\n",
      "394657133\n",
      "394657132\n",
      "394657131\n",
      "394151486\n",
      "394657138\n",
      "53160874\n",
      "3960987396\n",
      "3960987397\n",
      "117040604\n",
      "51865538\n",
      "394686816\n",
      "51865536\n",
      "3960987398\n",
      "3863104194\n",
      "116895731\n",
      "180987115\n",
      "51865530\n",
      "3882343526\n",
      "3992448342\n",
      "3882343520\n",
      "3882343521\n",
      "3992448343\n",
      "391950279\n",
      "3882343529\n",
      "93824158\n",
      "170010756\n",
      "93824152\n",
      "93824153\n",
      "93824154\n",
      "93824155\n",
      "3981178968\n",
      "3981178969\n",
      "391950280\n",
      "391950282\n",
      "393075940\n",
      "255676079\n",
      "1740520109\n",
      "392821854\n",
      "6019846\n",
      "69020389\n",
      "402585486\n",
      "3966868941\n",
      "402585488\n",
      "69020386\n",
      "69020387\n",
      "395178072\n",
      "94667003\n",
      "101476849\n",
      "69020401\n",
      "3966868942\n",
      "191237615\n",
      "400057816\n",
      "180986014\n",
      "109026455\n",
      "180986013\n",
      "393262104\n",
      "183472208\n",
      "1157145104\n",
      "1239454822\n",
      "395178075\n",
      "6028206\n",
      "396742888\n",
      "94667000\n",
      "393075935\n",
      "190295319\n",
      "190295318\n",
      "3994379439\n",
      "190295316\n",
      "396742887\n",
      "395165345\n",
      "358356921\n",
      "395165347\n",
      "3988926187\n",
      "103505681\n",
      "3983518157\n",
      "116896199\n",
      "396250181\n",
      "169914572\n",
      "3985368930\n",
      "3985368931\n",
      "3985368932\n",
      "3985368933\n",
      "94667001\n",
      "53160642\n",
      "395714614\n",
      "1294033584\n",
      "393475873\n",
      "1249440652\n",
      "394227006\n",
      "183340697\n",
      "68967484\n",
      "393475870\n",
      "109026452\n",
      "109026453\n",
      "109026451\n",
      "3980647952\n",
      "3980647951\n",
      "3980647950\n",
      "393233754\n",
      "190846344\n",
      "828418472\n",
      "169914164\n",
      "116896201\n",
      "384879605\n",
      "1043451567\n",
      "255676258\n",
      "102676632\n",
      "102676633\n",
      "116896203\n",
      "5862982\n",
      "183248496\n",
      "183248497\n",
      "400100820\n",
      "400100821\n",
      "395894000\n",
      "162976121\n",
      "395703564\n",
      "53160880\n",
      "184082095\n",
      "183327454\n",
      "53160886\n",
      "255677034\n",
      "334854362\n",
      "3273677166\n",
      "93835246\n",
      "66797088\n",
      "93835245\n",
      "107937233\n",
      "51865513\n",
      "1157145738\n",
      "114919313\n",
      "393274968\n",
      "393274969\n",
      "180987112\n",
      "396092143\n",
      "53217199\n",
      "5923588\n",
      "169913610\n",
      "394657134\n",
      "4030597721\n",
      "4030597720\n",
      "4030597722\n",
      "53256261\n",
      "93829839\n",
      "183802020\n",
      "3964475109\n",
      "184082086\n",
      "53160677\n",
      "184082085\n",
      "1239454013\n",
      "4029075398\n",
      "292998164\n"
     ]
    }
   ],
   "source": [
    "# Note: Below code was just to investigate a problem on the consistency of data classification between\n",
    "# data in XML and data in JSON format.\n",
    "\n",
    "# Get IDs of all different school nodes in the data set\n",
    "diff_restaurant = set()\n",
    "\n",
    "c=0\n",
    "\n",
    "for event, elem in ET.iterparse(filename):\n",
    "\n",
    "    # looking into node, way and realtions tags only\n",
    "    if elem.tag in (\"node\", \"way\", \"relation\"):\n",
    "        \n",
    "        for tag in elem.iter(\"tag\"):\n",
    "            if (tag.attrib['k'] == \"addr:postcode\"):\n",
    "                if tag.attrib['v'] == \"53202\":\n",
    "                    c = c+1\n",
    "                    diff_restaurant.add(elem.attrib.get(\"id\"))\n",
    "                    \n",
    "print \"Number of restaurant in Set():\"\n",
    "print len(diff_restaurant)\n",
    "print \"Number of iterations in \\\"school\\\" condition:\"\n",
    "print c\n",
    "\n",
    "print \"List all school id's:\"\n",
    "for rest in diff_restaurant:\n",
    "    print rest\n",
    "\n",
    "# Need to free up variables\n",
    "# in order to get RAM utilization managed   \n",
    "diff_restaurant = set()\n",
    "event = 0\n",
    "elem = 0\n",
    "c=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Conversion to JSON\n",
    "\n",
    "In this section the data file will be converted from XML to JSON format. At the same time some data cleaning activities will be performed. The resulting JSON data will be cleaned already.\n",
    "\n",
    "The need for data cleaning of different aspects of the data was analyst in earlier sections. This section picks up that information and develops strategies to clean up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Functions for Data Cleaning and Coversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nAbove the main constant variable have been defined and can be used later on in the analysis.\\n'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attribute containers\n",
    "PRIMARY  = [\"id\"] # main info from node attributes\n",
    "CREATION = [\"uid\", \"user\", \"changeset\", \"version\", \"timestamp\"] # info about creation of data point\n",
    "GEOPOS   = [\"lon\", \"lat\"] # info about geo location\n",
    "ADDRESS  = \"addr:\" # address info\n",
    "BUILDING = \"building:\" # building information\n",
    "CONTACT = \"contact:\"\n",
    "\n",
    "# Attribute containers for NODES\n",
    "N_PRIMARY_TAG = [\"name\", \"opening_hours\", \"operator\", \"phone\", \"website\", \"source\"] # info considered to be main info, but from inside TAG\n",
    "N_DEMOINFO = [\"place\", \"population\"] # demographic information\n",
    "N_ADDINFO  = [\"amenity\", \"cuisine\", \"fuel:diesel\", \"fuel:e10\", \"fuel:octane_91\", \"fuel:octane_95\", \"fuel:octane_98\", \"brand\", \\\n",
    "            \"shop\", \"denomination\", \"religion\", \"highway\"] # additional info about data point from inside TAG\n",
    "\n",
    "# Attribute containers for WAYS\n",
    "W_PRIMARY_TAG = [\"name\", \"source\", \"operator\", \"phone\", \"website\"]\n",
    "W_OBJECT_TAG = [\"highway\", \"leisure\", \"natural\", \"building\"] # info considered to be main info, but from inside TAG\n",
    "W_BUILDING_ATTS = [\"architect\", \"name:historic\"] # building information\n",
    "W_ADDINFO  = [\"oneway\", \"horse\", \"foot\", \"bicycle\", \"lanes\", \"oneway\", \"sidewalk\", \"amenity\"] # additional info about data point from inside TAG\n",
    "\n",
    "# Attribute containers for WAYS\n",
    "R_PRIMARY_TAG = [\"name\", \"source\", \"operator\", \"phone\", \"website\"]\n",
    "R_OBJECT_TAG = [\"highway\", \"leisure\", \"natural\", \"building\"] # info considered to be main info, but from inside TAG\n",
    "R_BUILDING_ATTS = [\"architect\", \"name:historic\"] # building information\n",
    "R_ADDINFO  = [\"place\", \"boundary\", \"admin_level\",\"oneway\", \"amenity\"] # additional info about data point from inside TAG\n",
    "\n",
    "# GNIS Attributes (USGS Geographic Names Information System) Pattern\n",
    "GNIS = \"gnis:\"\n",
    "'''\n",
    "    - Detailled Info about the attributes: http://wiki.openstreetmap.org/wiki/USGS_GNIS\n",
    "    - Sample Attributes:\n",
    "        ele = elevation\n",
    "        gnis:Class = Feature Class name\n",
    "        gnis:County = County name\n",
    "        gnis:County_num = County FIPS code\n",
    "        gnis:ST_alpha = State name (2-Letter abbreviation)\n",
    "        gnis:ST_num = State FIPS code\n",
    "        gnis:county_id = County FIPS code\n",
    "        gnis:created = MM/DD/YYYY when the GNIS entry was created\n",
    "        gnis:state_id = State FIPS code\n",
    "'''\n",
    "    \n",
    "# TIGER Attribute (Topologically Integrated Geographic Encoding and Referencing system) Pattern\n",
    "TIGER = \"tiger:\"\n",
    "''' \n",
    "    - Detailled Info about the attributes: http://wiki.openstreetmap.org/wiki/TIGER_to_OSM_Attribute_Map\n",
    "    - Sample Attributes:\n",
    "        tiger:cfcc\n",
    "        tiger:county\n",
    "        tiger:name_base\n",
    "        tiger:name_direction_prefix\n",
    "        tiger:name_type\n",
    "        tiger:reviewed\n",
    "        tiger:from_address_right\n",
    "        tiger:to_address_right\n",
    "        tiger:from_address_left\n",
    "        tiger:to_address_left\n",
    "        tiger:zip_left\n",
    "        tiger:zip_right\n",
    "        tiger:tlid\n",
    "        tiger:tzid\n",
    "'''\n",
    "\n",
    "''' \n",
    "Above the main constant variable have been defined and can be used later on in the analysis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update street names and update abbreviations with long term\n",
    "# problem with this function is that sometimes the names \n",
    "# are getting update wrongly\n",
    "# INPUT: name - street name\n",
    "# INPUT: mapping - street names to street name abbreviations\n",
    "def update_name_old(name, mapping):\n",
    "    for expr in mapping.keys():\n",
    "        if (expr in name) and (mapping[expr] not in name):\n",
    "            return name.replace(expr, mapping[expr])\n",
    "    return name\n",
    "\n",
    "# update street names and update abbreviations with long term\n",
    "# note: this function is based upon a solution provided at https://github.com/batmanbury/Udacity\n",
    "# INPUT: name - street name\n",
    "# INPUT: mapping - street names to street name abbreviations\n",
    "# RETURN: updated street name\n",
    "def update_name(name, mapping):\n",
    "    # split words in name\n",
    "    words = name.split()\n",
    "    # look at each word\n",
    "    for w in range(len(words)):\n",
    "        # check if word is set up in mapping variable\n",
    "        if words[w] in mapping:\n",
    "            words[w] = mapping[words[w]]\n",
    "    name = \" \".join(words)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove state abbr. of city tags\n",
    "# INPUT: name - street name\n",
    "# RETURN: updated street name\n",
    "def remove_state_abbr(name):\n",
    "    if \", \" in name:\n",
    "        temp =  name.lower().replace(\", wi\", \"\")\n",
    "        return string.capwords(temp)\n",
    "    else:\n",
    "        return string.capwords(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corrects some wrongly spelled street names based on a dictionary\n",
    "# INPUT: name - street name\n",
    "# RETURN: name - updated street name\n",
    "def correct_city_spelling(name):\n",
    "    if name in city_name_correction_mapping.keys():\n",
    "        return city_name_correction_mapping[name]\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removes \"-\" and \"_\" from strings\n",
    "# INPUT: name - certain string\n",
    "# RETURN: temp - updated string\n",
    "def remove_chars(name):\n",
    "    temp =  name.lower().replace(\"-\", \" \")\n",
    "    temp =  name.lower().replace(\"_\", \" \")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert a node object to a python dict / JSON object string\n",
    "# INPUT: elem - element in XML data\n",
    "# RETURN: node - in JSON string format\n",
    "def convert_node_to_json(elem):\n",
    "    \n",
    "    # NODE dict\n",
    "    node = {} # main information container\n",
    "    \n",
    "    # SUB dicts\n",
    "    creation = {}  # basic info about data creation\n",
    "    address  = {}  # geopraphic information\n",
    "    demoinfo = {}  # demographic information\n",
    "    geopos   = {}  # geopraphic information\n",
    "    addinfo  = {}  # some additional info about the datapoint\n",
    "    gnis     = {}  # all GNIS attributes for the datapoint\n",
    "    tiger    = {}  # all TIGER attributes for the datapoint\n",
    "    other    = {}  # all other info\n",
    "    \n",
    "    # type is always \"node\" \n",
    "    node[\"type\"] = \"node\" \n",
    "    \n",
    "    # main attributes\n",
    "    for key in elem.attrib:\n",
    "        \n",
    "        # grapping the main attributes\n",
    "         ##############################################\n",
    "        # main node info\n",
    "        if key in PRIMARY:\n",
    "            node[key] = elem.attrib.get(key) \n",
    "        \n",
    "        ##############################################\n",
    "        # sub node info\n",
    "        elif key in CREATION:\n",
    "            creation[key] = elem.attrib.get(key) \n",
    "                \n",
    "        elif key in GEOPOS:\n",
    "            geopos[key] = elem.attrib.get(key)\n",
    "    \n",
    "    # grapping sub info\n",
    "    for tag in elem.iter():\n",
    "        if tag.tag == \"tag\":\n",
    "            \n",
    "            ##############################################\n",
    "            # main node info\n",
    "            if tag.attrib['k'] in N_PRIMARY_TAG:\n",
    "                 node[tag.attrib['k']] = tag.attrib['v']\n",
    "            \n",
    "            ##############################################\n",
    "            # sub node info\n",
    "            ##### all atts for creation dict\n",
    "            elif tag.attrib['k'] in CREATION:\n",
    "                creation[tag.attrib['k']] = tag.attrib['v']  \n",
    "             \n",
    "            ##### all atts for demographic information dict    \n",
    "            elif tag.attrib['k'] in N_DEMOINFO:\n",
    "                demoinfo[tag.attrib['k']] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for address dict\n",
    "            elif ADDRESS in tag.attrib['k'] :\n",
    "                 # cleaning street data\n",
    "                if is_street_name(tag):\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = update_name(tag.attrib['v'], street_name_mapping)\n",
    "                # cleaning city data\n",
    "                elif is_city(tag):\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = correct_city_spelling(remove_state_abbr(tag.attrib['v']))\n",
    "                # all other cases\n",
    "                else:\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for additional information dict\n",
    "            elif tag.attrib['k'] in N_ADDINFO:\n",
    "                \n",
    "                # special case for fuel stations\n",
    "                if is_amenity(tag):\n",
    "                    if tag.attrib['v'] == \"fuel\":\n",
    "                        addinfo[\"type\"] = \"shop\"\n",
    "                        addinfo[\"shop_type\"] = \"fuel\"\n",
    "                    else:\n",
    "                        addinfo[\"type\"] = remove_chars(tag.attrib['v'])\n",
    "                \n",
    "                # other types of shops\n",
    "                elif is_shop(tag):\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            addinfo[\"type_details\"] = \"shop\"\n",
    "                            addinfo[\"shop_type\"] = remove_chars(tag.attrib['v'])\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"shop\"\n",
    "                        addinfo[\"shop_type\"] = remove_chars(tag.attrib['v'])\n",
    "                    \n",
    "                # other types of shops\n",
    "                elif is_highway(tag):\n",
    "                    addinfo[\"street_info\"] = tag.attrib['v']\n",
    "                \n",
    "                else:\n",
    "                    addinfo[tag.attrib['k']] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif GNIS in tag.attrib['k'] or tag.attrib['k'] == 'ele':\n",
    "                gnis[tag.attrib['k'].replace(\"gnis:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for TIGER information dict\n",
    "            elif TIGER in tag.attrib['k']:\n",
    "                tiger[tag.attrib['k'].replace(\"tiger:\", \"\")] = tag.attrib['v']  \n",
    "            \n",
    "            ##### all atts for other dict\n",
    "            else:\n",
    "                other[tag.attrib['k']] = tag.attrib['v']   \n",
    "            \n",
    "    \n",
    "    # put all the pieces together as they are available\n",
    "    if len(creation) > 0:\n",
    "        node[\"creation\"] = creation\n",
    "    if len(address) > 0:\n",
    "        node[\"address\"]  = address\n",
    "    if len(demoinfo) > 0:\n",
    "        node[\"demoinfo\"] = demoinfo\n",
    "    if len(geopos) > 0:\n",
    "        node[\"geopos\"]   = geopos\n",
    "    if len(addinfo) > 0:\n",
    "        node[\"addinfo\"]  = addinfo\n",
    "    if len(gnis) > 0:\n",
    "        node[\"gnis\"]     = gnis\n",
    "    if len(tiger) > 0:\n",
    "        node[\"tiger\"]    = tiger\n",
    "    if len(other) > 0:\n",
    "        node[\"other\"]    = other\n",
    "        \n",
    "    # Need to free up variables\n",
    "    # in order to get RAM utilization managed\n",
    "    creation = {}  \n",
    "    address  = {}  \n",
    "    demoinfo = {}  \n",
    "    geopos   = {}  \n",
    "    addinfo  = {}  \n",
    "    gnis     = {}  \n",
    "    tiger    = {}  \n",
    "    other    = {}  \n",
    "        \n",
    "    # return the node as a dict object\n",
    "    return node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert a way object to a python dict / JSON object string\n",
    "# INPUT: elem - element in XML data\n",
    "# RETURN: node - in JSON string format\n",
    "def convert_way_to_json(elem):\n",
    "    # NODE dict\n",
    "    way = {} # main information container\n",
    "    \n",
    "    # SUB dicts\n",
    "    creation = {}  # basic info about data creation\n",
    "    address  = {}  # geopraphic information\n",
    "    contact  = {}  # contact information\n",
    "    building = {}  # building information\n",
    "    area     = {}  # area information\n",
    "    geopos   = {}  # geopraphic information\n",
    "    addinfo  = {}  # some additional info about the datapoint\n",
    "    gnis     = {}  # all GNIS attributes for the datapoint\n",
    "    tiger    = {}  # all TIGER attributes for the datapoint\n",
    "    nds      = []   # nd references\n",
    "    other    = {}  # all other info\n",
    "    \n",
    "    # type is always \"node\" \n",
    "    way[\"type\"] = \"way\" \n",
    "    \n",
    "    # main attributes\n",
    "    for key in elem.attrib:\n",
    "        \n",
    "        # grapping the main attributes\n",
    "         ##############################################\n",
    "        # main node info\n",
    "        if key in PRIMARY:\n",
    "            way[key] = elem.attrib.get(key) \n",
    "        \n",
    "        ##############################################\n",
    "        # sub node info\n",
    "        elif key in CREATION:\n",
    "            creation[key] = elem.attrib.get(key) \n",
    "                \n",
    "        elif key in GEOPOS:\n",
    "            geopos[key] = elem.attrib.get(key)\n",
    "    \n",
    "    # grapping sub info\n",
    "    for tag in elem.iter():\n",
    "        if tag.tag == \"tag\":\n",
    "            \n",
    "            ##############################################\n",
    "            # main node info\n",
    "            if tag.attrib['k'] in W_PRIMARY_TAG:\n",
    "                 way[tag.attrib['k']] = tag.attrib['v']\n",
    "            \n",
    "            ##############################################\n",
    "            # sub node info\n",
    "            ##### all atts for creation dict\n",
    "            elif tag.attrib['k'] in CREATION:\n",
    "                creation[tag.attrib['k']] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for address dict\n",
    "            elif ADDRESS in tag.attrib['k']:\n",
    "                 # cleaning street data\n",
    "                if is_street_name(tag):\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = update_name(tag.attrib['v'], street_name_mapping)\n",
    "                # cleaning city data\n",
    "                elif is_city(tag):\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = correct_city_spelling(remove_state_abbr(tag.attrib['v']))\n",
    "                # all other cases\n",
    "                else:\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for additional information dict\n",
    "            elif (tag.attrib['k'] in W_ADDINFO) or (tag.attrib['k'] in W_OBJECT_TAG):\n",
    "                \n",
    "                # special cases if way has a amenity tag\n",
    "                if is_amenity(tag):\n",
    "                    addinfo[\"type\"] = remove_chars(tag.attrib['v'])\n",
    "                \n",
    "                # other types of shops\n",
    "                elif is_shop(tag):\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            addinfo[\"type_details\"] = \"shop\"\n",
    "                            addinfo[\"shop_type\"] = remove_chars(tag.attrib['v'])\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"shop\"\n",
    "                        addinfo[\"shop_type\"] = remove_chars(tag.attrib['v'])\n",
    "                    \n",
    "                # other types of shops\n",
    "                elif tag.attrib['k'] in [\"highway\", \"leisure\", \"natural\"]:\n",
    "                    addinfo[\"type\"] = tag.attrib['k']\n",
    "                    addinfo[\"type_details\"] = tag.attrib['v']\n",
    "                    \n",
    "                elif is_building(tag) and tag.attrib['v'] != \"yes\":\n",
    "                    building[\"building_type\"] = tag.attrib['v']\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            addinfo[\"type\"] = \"building\"\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"building\"\n",
    "                \n",
    "                elif is_building(tag) and tag.attrib['v'] == \"yes\":\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            addinfo[\"type\"] = \"building\"\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"building\"\n",
    "                \n",
    "                else:\n",
    "                    addinfo[tag.attrib['k']] = tag.attrib['v']  \n",
    "            \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif CONTACT in tag.attrib['k']:\n",
    "                contact[tag.attrib['k'].replace(\"contact:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif BUILDING in tag.attrib['k'] or \\\n",
    "                 tag.attrib['k'] in [\"name:historic\", \"architect\", \"building\"]:\n",
    "                # capture all attributes in a sub sub node\n",
    "                building[tag.attrib['k'].replace(\"building:\", \"\")] = tag.attrib['v']\n",
    "                try:\n",
    "                    if len(addinfo[\"type\"]) == 0:\n",
    "                        addinfo[\"type\"] = \"building\"\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    addinfo[\"type\"] = \"building\"\n",
    "                \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif GNIS in tag.attrib['k'] or tag.attrib['k'] == 'ele':\n",
    "                gnis[tag.attrib['k'].replace(\"gnis:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for TIGER information dict\n",
    "            elif TIGER in tag.attrib['k']:\n",
    "                tiger[tag.attrib['k'].replace(\"tiger:\", \"\")] = tag.attrib['v']  \n",
    "            \n",
    "            ##### all atts for other dict\n",
    "            else:\n",
    "                other[tag.attrib['k']] = tag.attrib['v']   \n",
    "        \n",
    "        elif tag.tag == \"nd\":\n",
    "            nd = {}\n",
    "            nd[\"ref\"]  = tag.attrib['ref']\n",
    "            nds.append(nd)            \n",
    "    \n",
    "    # put all the pieces together as they are available\n",
    "    if len(creation) > 0:\n",
    "        way[\"creation\"] = creation\n",
    "    if len(address) > 0:\n",
    "        way[\"address\"]  = address\n",
    "    if len(building) > 0:\n",
    "        addinfo[\"building\"] = building\n",
    "    if len(area) > 0:\n",
    "        way[\"area\"]     = area\n",
    "    if len(geopos) > 0:\n",
    "        way[\"geopos\"]   = geopos\n",
    "    if len(addinfo) > 0:\n",
    "        way[\"addinfo\"]  = addinfo\n",
    "    if len(gnis) > 0:\n",
    "        way[\"gnis\"]     = gnis\n",
    "    if len(tiger) > 0:\n",
    "        way[\"tiger\"]    = tiger\n",
    "    if len(nds) > 0:\n",
    "        way[\"nds\"]    = nds\n",
    "    if len(other) > 0:\n",
    "        way[\"other\"]    = other\n",
    "    \n",
    "    # Need to free up variables\n",
    "    # in order to get RAM utilization managed\n",
    "    creation = {} \n",
    "    address  = {}  \n",
    "    contact  = {}  \n",
    "    building = {}  \n",
    "    area     = {}  \n",
    "    geopos   = {}  \n",
    "    addinfo  = {}  \n",
    "    gnis     = {}  \n",
    "    tiger    = {}  \n",
    "    nds      = []  \n",
    "    other    = {}  \n",
    "\n",
    "    \n",
    "    # return the node as a dict object\n",
    "    return way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert a relation object to a python dict / JSON object string\n",
    "# INPUT: elem - element in XML data\n",
    "# RETURN: node - in JSON string format\n",
    "def convert_relation_to_json(elem):\n",
    "     # NODE dict\n",
    "    relation = {} # main information container\n",
    "    \n",
    "    # SUB dicts\n",
    "    creation = {}  # basic info about data creation\n",
    "    address  = {}  # geopraphic information\n",
    "    contact  = {}  # contact information\n",
    "    building = {}  # building information\n",
    "    area     = {}  # area information\n",
    "    geopos   = {}  # geopraphic information\n",
    "    addinfo  = {}  # some additional info about the datapoint\n",
    "    gnis     = {}  # all GNIS attributes for the datapoint\n",
    "    tiger    = {}  # all TIGER attributes for the datapoint\n",
    "    members  = []  # all members of datapoint\n",
    "    other    = {}  # all other info\n",
    "    \n",
    "    # type is always \"node\" \n",
    "    relation[\"type\"] = \"relation\" \n",
    "    \n",
    "    # main attributes\n",
    "    for key in elem.attrib:\n",
    "        \n",
    "        # grapping the main attributes\n",
    "         ##############################################\n",
    "        # main node info\n",
    "        if key in PRIMARY:\n",
    "            relation[key] = elem.attrib.get(key) \n",
    "        \n",
    "        ##############################################\n",
    "        # sub node info\n",
    "        elif key in CREATION:\n",
    "            creation[key] = elem.attrib.get(key) \n",
    "    \n",
    "    # grapping sub info\n",
    "    for tag in elem.iter():\n",
    "        if tag.tag == \"tag\":\n",
    "            \n",
    "            ##############################################\n",
    "            # main node info\n",
    "            if tag.attrib['k'] in R_PRIMARY_TAG:\n",
    "                 relation[tag.attrib['k']] = tag.attrib['v']\n",
    "            \n",
    "            ##############################################\n",
    "            # sub node info\n",
    "            ##### all atts for creation dict\n",
    "            elif tag.attrib['k'] in CREATION:\n",
    "                creation[tag.attrib['k']] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for address dict\n",
    "            elif ADDRESS in tag.attrib['k']:\n",
    "                 # cleaning street data\n",
    "                if is_street_name(tag):\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = update_name(tag.attrib['v'], street_name_mapping)\n",
    "                # cleaning city data\n",
    "                elif is_city(tag):\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = correct_city_spelling(remove_state_abbr(tag.attrib['v']))\n",
    "                # all other cases\n",
    "                else:\n",
    "                    address[tag.attrib['k'].replace(\"addr:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for additional information dict\n",
    "            elif (tag.attrib['k'] in R_ADDINFO) or (tag.attrib['k'] in R_OBJECT_TAG):\n",
    "                \n",
    "                # special cases if way has a amenity tag\n",
    "                if is_amenity(tag):\n",
    "                    addinfo[\"type\"] = remove_chars(tag.attrib['v'])\n",
    "                \n",
    "                # other types of shops\n",
    "                elif is_shop(tag):\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            addinfo[\"type_details\"] = \"shop\"\n",
    "                            addinfo[\"shop_type\"] = remove_chars(tag.attrib['v'])\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"shop\"\n",
    "                        addinfo[\"shop_type\"] = remove_chars(tag.attrib['v'])\n",
    "                    \n",
    "                # other objct types\n",
    "                elif tag.attrib['k'] in [\"highway\", \"leisure\", \"natural\"]:\n",
    "                    addinfo[\"type\"] = tag.attrib['k']\n",
    "                    addinfo[\"type_details\"] = tag.attrib['v']\n",
    "                    \n",
    "                elif is_building(tag) and tag.attrib['v'] != \"yes\":\n",
    "                    building[\"building_type\"] = tag.attrib['v']\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            addinfo[\"type\"] = \"building\"\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"building\"\n",
    "                \n",
    "                elif is_building(tag) and tag.attrib['v'] == \"yes\":\n",
    "                    try:\n",
    "                        if len(addinfo[\"type\"]) == 0:\n",
    "                            addinfo[\"type\"] = \"building\"\n",
    "                        else:\n",
    "                            pass\n",
    "                    except:\n",
    "                        addinfo[\"type\"] = \"building\"\n",
    "                \n",
    "                else:\n",
    "                    addinfo[tag.attrib['k']] = tag.attrib['v']  \n",
    "            \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif CONTACT in tag.attrib['k']:\n",
    "                contact[tag.attrib['k'].replace(\"contact:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif BUILDING in tag.attrib['k'] or \\\n",
    "                 tag.attrib['k'] in [\"name:historic\", \"architect\", \"building\"]:\n",
    "                # capture all attributes in a sub sub node\n",
    "                building[tag.attrib['k'].replace(\"building:\", \"\")] = tag.attrib['v']\n",
    "                try:\n",
    "                    if len(addinfo[\"type\"]) == 0:\n",
    "                        addinfo[\"type\"] = \"building\"\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    addinfo[\"type\"] = \"building\"\n",
    "                    \n",
    "            ##### all atts for GNIS information dict\n",
    "            elif GNIS in tag.attrib['k'] or tag.attrib['k'] == 'ele':\n",
    "                gnis[tag.attrib['k'].replace(\"gnis:\", \"\")] = tag.attrib['v']  \n",
    "                \n",
    "            ##### all atts for TIGER information dict\n",
    "            elif TIGER in tag.attrib['k']:\n",
    "                tiger[tag.attrib['k'].replace(\"tiger:\", \"\")] = tag.attrib['v']  \n",
    "            \n",
    "            ##### all atts for other dict\n",
    "            else:\n",
    "                if is_type(tag):\n",
    "                    relation[\"relation_type\"] = tag.attrib['v']\n",
    "                else:\n",
    "                    other[tag.attrib['k']] = tag.attrib['v']   \n",
    "             \n",
    "        elif tag.tag == \"member\":\n",
    "            member = {}\n",
    "            member[\"type\"] = tag.attrib['type']\n",
    "            member[\"ref\"]  = tag.attrib['ref']\n",
    "            member[\"role\"] = tag.attrib['role']\n",
    "            members.append(member)\n",
    "    \n",
    "    # put all the pieces together as they are available\n",
    "    if len(creation) > 0:\n",
    "        relation[\"creation\"] = creation\n",
    "    if len(address) > 0:\n",
    "        relation[\"address\"]  = address\n",
    "    if len(building) > 0:\n",
    "        addinfo[\"building\"] = building\n",
    "    if len(area) > 0:\n",
    "        relation[\"area\"]     = area\n",
    "    if len(addinfo) > 0:\n",
    "        relation[\"addinfo\"]  = addinfo\n",
    "    if len(gnis) > 0:\n",
    "        relation[\"gnis\"]     = gnis\n",
    "    if len(tiger) > 0:\n",
    "        relation[\"tiger\"]    = tiger\n",
    "    if len(members) > 0:\n",
    "        relation[\"members\"]    = members\n",
    "    if len(other) > 0:\n",
    "        relation[\"other\"]    = other\n",
    "    \n",
    "    # Need to free up variables\n",
    "    # in order to get RAM utilization managed\n",
    "    creation = {}\n",
    "    address  = {}\n",
    "    contact  = {}\n",
    "    building = {}\n",
    "    area     = {}\n",
    "    geopos   = {}\n",
    "    addinfo  = {}\n",
    "    gnis     = {}\n",
    "    tiger    = {}\n",
    "    members  = []\n",
    "    other    = {}\n",
    "    \n",
    "    # return the node as a dict object\n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main data cleaning and concersion funtion\n",
    "# INPUT: osmfile - filename of XML file\n",
    "# RETURN: data_final - array with JSON data inside\n",
    "def convert_to_json(osmfile):\n",
    "    \n",
    "    # open xml file\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    \n",
    "    # main data containers\n",
    "    data_final = []\n",
    "    \n",
    "    # line by line walk\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        \n",
    "        # main data nodes\n",
    "        osm = {}\n",
    "        note = {}\n",
    "        meta = {}\n",
    "        bounds = {}\n",
    "        node = {}\n",
    "        way = {}\n",
    "        relation = {}\n",
    "        \n",
    "        # sub data nodes\n",
    "        tags_cont = []\n",
    "        nds_cont = []\n",
    "        members_cont = []\n",
    "        \n",
    "        ##############################################\n",
    "        # converting header information nodes\n",
    "        ##############################################\n",
    "        if elem.tag == \"osm\":\n",
    "            osm[\"type\"] = \"osm\"\n",
    "            osm[\"content\"] = elem.attrib\n",
    "            if len(osm) > 0:\n",
    "                data_final.append(osm)\n",
    "        \n",
    "        elif elem.tag == \"note\":\n",
    "            note[\"type\"] = \"note\"\n",
    "            note[\"content\"]= elem.text\n",
    "            if len(note) > 0:\n",
    "                data_final.append(note)\n",
    "        \n",
    "        elif elem.tag == \"meta\":\n",
    "            meta[\"type\"] = \"meta\"\n",
    "            meta[\"content\"] = elem.attrib\n",
    "            if len(meta) > 0:\n",
    "                data_final.append(meta)\n",
    "        \n",
    "        elif elem.tag == \"bounds\":\n",
    "            bounds[\"type\"] = \"bounds\"\n",
    "            bounds[\"content\"] = elem.attrib\n",
    "            if len(bounds) > 0:\n",
    "                data_final.append(bounds)\n",
    "        \n",
    "        ##############################################\n",
    "        # converting node tags\n",
    "        ##############################################\n",
    "        elif elem.tag == \"node\":\n",
    "            # call function to convert node data into json\n",
    "            node = convert_node_to_json(elem)\n",
    "            # add to nodes\n",
    "            if len(node) > 0:\n",
    "                data_final.append(node)\n",
    "        elif elem.tag == \"way\":\n",
    "            # call function to convert node data into json\n",
    "            way = convert_way_to_json(elem)\n",
    "            # add to nodes\n",
    "            if len(way) > 0:\n",
    "                data_final.append(way)\n",
    "        elif elem.tag == \"relation\":\n",
    "            # call function to convert node data into json\n",
    "            relation = convert_relation_to_json(elem)\n",
    "            # add to nodes\n",
    "            if len(relation) > 0:\n",
    "                data_final.append(relation)    \n",
    "                \n",
    "    # Need to free up variables\n",
    "    # in order to get RAM utilization managed                \n",
    "    # main data nodes\n",
    "    osm = {}\n",
    "    note = {}\n",
    "    meta = {}\n",
    "    bounds = {}\n",
    "    node = {}\n",
    "    way = {}\n",
    "    relation = {}\n",
    "    tags_cont = []\n",
    "    nds_cont = []\n",
    "    members_cont = []     \n",
    "                \n",
    "        \n",
    "    return data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the XML file into the defined JSON format\n",
    "# call of main XML to JSON convertion\n",
    "data = convert_to_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definition of json file name\n",
    "json_filename = \"waukesha_county_osm.json\"\n",
    "\n",
    "# create json file based on python dict prepared above\n",
    "with open(json_filename, 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "\n",
    "# free up variable\n",
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of OSM JSON data file: \n",
      "243607 KB\n"
     ]
    }
   ],
   "source": [
    "# Return the size, in bytes, of path. Raise os.error if the file does not exist or is inaccessible.\n",
    "print \"Size of OSM JSON data file: \"\n",
    "print (str(os.path.getsize(json_filename)/1024)) + \" KB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully dropped existing DB and created database osm_data\n"
     ]
    }
   ],
   "source": [
    "# get client to local mongoDB instance\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "\n",
    "db_name = \"osm_data\"\n",
    "\n",
    "# try to create new database osm_data, drop and recreate if already exists\n",
    "try:\n",
    "    client.drop_database(db_name)\n",
    "    db = client.osm_data\n",
    "    print \"Successfully dropped existing DB and created database \" + str(db_name)\n",
    "\n",
    "# catch case if database does not exist and therfore can not be dropped\n",
    "except:\n",
    "    try:\n",
    "        db = client.osm_data\n",
    "        print \"Successfully created new database \"  + str(db_name)\n",
    "    except:\n",
    "        print \"Issues creating new Database \" + str(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(json_filename) as f:\n",
    "    data_for_import = json.loads(f.read())\n",
    "    # perform insert to MongoDB\n",
    "    db.wau_county.insert_many(data_for_import)\n",
    "\n",
    "# free up variable    \n",
    "data_for_import = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating some indexes which will speed up our queries later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes created\n"
     ]
    }
   ],
   "source": [
    "db.wau_county.create_index(\"id\")\n",
    "db.wau_county.create_index(\"type\")\n",
    "db.wau_county.create_index(\"addinfo.type\")\n",
    "db.wau_county.create_index(\"creation.user\")\n",
    "db.wau_county.create_index(\"address.city\")\n",
    "print \"Indexes created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Key Types & Count ------------------\n",
      "Nr. of Documents: 953864\n",
      "--------------------------\n",
      "Nr. of Nodes:     860835\n",
      "Nr. of Ways:      92239\n",
      "Nr. of Relations: 786\n"
     ]
    }
   ],
   "source": [
    "# Number of Documents\n",
    "num_docs  = db.wau_county.find().count()\n",
    "num_nodes = db.wau_county.find({\"type\":\"node\"}).count()\n",
    "num_ways  = db.wau_county.find({\"type\":\"way\"}).count()\n",
    "num_rels  = db.wau_county.find({\"type\":\"relation\"}).count()\n",
    "\n",
    "print('--------------- Key Types & Count ------------------')\n",
    "print('Nr. of Documents: ' + str(num_docs))\n",
    "print('--------------------------')\n",
    "print('Nr. of Nodes:     ' + str(num_nodes))\n",
    "print('Nr. of Ways:      ' + str(num_ways))\n",
    "print('Nr. of Relations: ' + str(num_rels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers for Nodes, Ways and Relations is consistent with the numbers gathered earlier on XML basis (see Key Types & Count). Means, thus far it looks like the migration from XML to JSON as well as the import into MongoDB was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Users ------------------\n",
      "Number of unique users: 682\n",
      "----------------------------------------\n",
      "First 10 users in the list:\n",
      "woodpeck_fixbot: 217089\n",
      "ItalianMustache: 102449\n",
      "shuui: 94917\n",
      "hogrod: 48592\n",
      "reschultzed: 40931\n",
      "bbauter: 29704\n",
      "Mulad: 28162\n",
      "Gary Cox: 27193\n",
      "iandees: 26923\n",
      "TIGERcnl: 25893\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('--------------- Users ------------------')\n",
    "unique_users = len(db.wau_county.distinct(\"creation.user\"))\n",
    "print('Number of unique users: ' + str(unique_users))\n",
    "print('----------------------------------------')\n",
    "aggregation_query = [{\"$group\" : {\"_id\" : \"$creation.user\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}},\n",
    "                     {\"$limit\" : 10}]\n",
    "top_users = db.wau_county.aggregate(aggregation_query)\n",
    "print('First 10 users in the list:')\n",
    "for user in top_users:\n",
    "    print user[\"_id\"] + \": \" + str(user[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 users and the number of their posts is consistent with the numbers gathered earlier on XML basis (see Users). Means again, thus far it looks like the migration from XML to JSON as well as the import into MongoDB was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Amenity Types -------------------\n",
      "Below is a list of different amenities and and their\n",
      "occurence in the data.\n",
      "----------------------------------------------------\n",
      "First 10 users in the list:\n",
      "highway: 62601\n",
      "building: 11053\n",
      "leisure: 2438\n",
      "parking: 2304\n",
      "natural: 2012\n",
      "school: 997\n",
      "shop: 694\n",
      "parking entrance: 569\n",
      "restaurant: 444\n",
      "fast food: 230\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '------------------ Amenity Types -------------------'\n",
    "print 'Below is a list of different amenities and and their'\n",
    "print 'occurence in the data.'\n",
    "print '----------------------------------------------------'\n",
    "aggregation_query = [\n",
    "                     {\"$match\" : { \"addinfo.type\" : {\"$exists\" : True } }},\n",
    "                     {\"$group\" : {\"_id\" : \"$addinfo.type\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}},\n",
    "                     {\"$limit\" : 10}\n",
    "                    ]\n",
    "info_types = db.wau_county.aggregate(aggregation_query)\n",
    "print('First 10 users in the list:')\n",
    "for info in info_types:\n",
    "    print str(info[\"_id\"]) + \": \" + str(info[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amenities list looks a bit different now. Reason for that is that the data has been restructured and thereby amenity information, but also other information like highway, building, leisure, natural, etcs. has been clubbed together into a new addinfo.type attribute. In that attribute basically describes what the data point is, independent of the main type (node, relation, way). It provides a more comprehensive insight to the data and makes searching for specific types of nodes, ways and relations easier.\n",
    "\n",
    "However, there was an issue I had to invest in detail. Sometime, the count in the XML data was higher than the one in the MongoDB. An example for that is: school, restaurant, shops. During my investigations I found out that sometimes the migration procedure from XML to JSON was overwriting some values for \"addinfo.type\" in JSON format. For example if there was a restaurant which was a butcher shop too, in addition of being a restaurant. \n",
    "\n",
    "One example of an issue with an \"amenity\" = \"parking\" which was migrated to an \"addinfo.type\" = \"leisure\" is added in the submission in file issue_example.txt. Here, due to the restructuring of some data during the migration process, the value for \"addinfo.type\" is overwritten by \"addinfo.type\" = \"leisure\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Post Codes -------------------\n",
      "Below is a list of all post codes and and their\n",
      "occurence in the data.\n",
      "-------------------------------------------------\n",
      "First 10 post codes in the list:\n",
      "53202: 993\n",
      "53212: 255\n",
      "53203: 229\n",
      "53538: 143\n",
      "53233: 132\n",
      "53211: 93\n",
      "53204: 67\n",
      "53215: 47\n",
      "53094: 42\n",
      "53027: 38\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '------------------ Post Codes -------------------'\n",
    "print 'Below is a list of all post codes and and their'\n",
    "print 'occurence in the data.'\n",
    "print '-------------------------------------------------'\n",
    "aggregation_query = [\n",
    "                     {\"$match\" : { \"address.postcode\" : {\"$exists\" : True }}},\n",
    "                     {\"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}},\n",
    "                     {\"$limit\" : 10}\n",
    "                    ]\n",
    "post_codes = db.wau_county.aggregate(aggregation_query)\n",
    "print('First 10 post codes in the list:')\n",
    "for post_code in post_codes:\n",
    "    print str(post_code[\"_id\"]) + \": \" + str(post_code[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result is equal to XML based result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Correct Post Code Types ---------------\n",
      "Below is a list of post codes which do not belong to\n",
      "Waukesha County and their occurence in the data.\n",
      "----------------------------------------------------\n",
      "First 10 post codes in the list:\n",
      "53186: 23\n",
      "53029: 23\n",
      "53066: 12\n",
      "53072: 11\n",
      "53045: 11\n",
      "53051: 10\n",
      "53005: 9\n",
      "53188: 8\n",
      "53151: 7\n",
      "53069: 3\n",
      "53146: 3\n",
      "53149: 3\n",
      "53189: 2\n",
      "53122: 2\n",
      "53089: 2\n",
      "53150: 2\n",
      "53183: 1\n",
      "53018: 1\n",
      "53103: 1\n",
      "53007: 1\n",
      "53187: 1\n",
      "53153: 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '-------------- Correct Post Code Types ---------------'\n",
    "print 'Below is a list of post codes which do not belong to'\n",
    "print 'Waukesha County and their occurence in the data.'\n",
    "print '----------------------------------------------------'\n",
    "aggregation_query = [\n",
    "                     {\"$match\" : { \"address.postcode\" : {\"$exists\" : True } } },\n",
    "                     {\"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1} } },\n",
    "                     {\"$sort\" : {\"count\":-1} }\n",
    "                    ]\n",
    "post_codes = db.wau_county.aggregate(aggregation_query)\n",
    "print('First 10 post codes in the list:')\n",
    "for post_code in post_codes:\n",
    "    # this checks if the post code is in the post codes of waukesha county area\n",
    "    if post_code[\"_id\"] in post_code_expected:\n",
    "        print str(post_code[\"_id\"]) + \": \" + str(post_code[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result is equal to XML based result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Wrong Post Code Types ---------------\n",
      "Below is a list of post codes which do not belong to\n",
      "Waukesha County and their occurence in the data.\n",
      "----------------------------------------------------\n",
      "First 10 post codes in the list:\n",
      "53202: 993\n",
      "53212: 255\n",
      "53203: 229\n",
      "53538: 143\n",
      "53233: 132\n",
      "53211: 93\n",
      "53204: 67\n",
      "53215: 47\n",
      "53094: 42\n",
      "53027: 38\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '-------------- Wrong Post Code Types ---------------'\n",
    "print 'Below is a list of post codes which do not belong to'\n",
    "print 'Waukesha County and their occurence in the data.'\n",
    "print '----------------------------------------------------'\n",
    "c = 0\n",
    "aggregation_query = [\n",
    "                     {\"$match\" : { \"address.postcode\" : {\"$exists\" : True }}},\n",
    "                     {\"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "post_codes = db.wau_county.aggregate(aggregation_query)\n",
    "print('First 10 post codes in the list:')\n",
    "for post_code in post_codes:\n",
    "    c = c+1\n",
    "    # this checks if the post code is in the post codes of waukesha county area\n",
    "    if post_code[\"_id\"] not in post_code_expected:\n",
    "        print str(post_code[\"_id\"]) + \": \" + str(post_code[\"count\"])\n",
    "    \n",
    "    # exit loop after 10 times  \n",
    "    if c == 10:\n",
    "        break\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result is equal to XML based result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Wrong Post Code Types ---------------\n",
      "Below is a list of post codes which do not match an\n",
      "extended pattern around Waukesha County and their\n",
      "occurence in the data.\n",
      "Pattern: (1) 53000 - 53599 and\n",
      "         (2) length of post code is 5 chars\n",
      "u'54220'\n",
      "u'1729'\n",
      "u'53203-3099'\n",
      "u'53217-5399'\n",
      "u'53214-3110'\n",
      "u'53403-9998'\n",
      "u'Milwaukee WI, 53222'\n",
      "u'WI'\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '-------------- Wrong Post Code Types ---------------'\n",
    "print 'Below is a list of post codes which do not match an'\n",
    "print 'extended pattern around Waukesha County and their'\n",
    "print 'occurence in the data.'\n",
    "print 'Pattern: (1) 53000 - 53599 and'\n",
    "print '         (2) length of post code is 5 chars'\n",
    "c = 0\n",
    "aggregation_query = [\n",
    "                     {\"$match\" : { \"address.postcode\" : {\"$exists\" : True }}},\n",
    "                     {\"$group\" : {\"_id\" : \"$address.postcode\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "post_codes = db.wau_county.aggregate(aggregation_query)\n",
    "for post_code_info in post_codes:\n",
    "    post_code = post_code_info[\"_id\"]\n",
    "    # check agains regex for valid post codes\n",
    "    is_valid_post_code = post_code_re.match(post_code)\n",
    "    # if post code does not match expected pattern or post code length is not 5\n",
    "    if (not is_valid_post_code) or (len(post_code) != 5):\n",
    "        pprint.pprint(post_code)\n",
    "    # exit loop after 10 times  \n",
    "    if c == 10:\n",
    "        break\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result is equal to XML based result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Cities in the dataset ---------------\n",
      "Below is a list of different cities mentioned in the\n",
      "data and their occurence.\n",
      "----------------------------------------------------\n",
      "First 10 users in the list:\n",
      "Milwaukee: 1622\n",
      "Racine: 561\n",
      "Fort Atkinson: 145\n",
      "Mount Pleasant: 120\n",
      "Waterloo: 57\n",
      "Watertown: 46\n",
      "Waukesha: 34\n",
      "Caledonia: 29\n",
      "Sturtevant: 27\n",
      "Hartland: 21\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '-------------- Cities in the dataset ---------------'\n",
    "print 'Below is a list of different cities mentioned in the'\n",
    "print 'data and their occurence.'\n",
    "print '----------------------------------------------------'\n",
    "aggregation_query = [{\"$match\" : { \"address.city\" : {\"$exists\" : True }}},\n",
    "                     {\"$group\" : {\"_id\" : \"$address.city\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}},\n",
    "                     {\"$limit\" : 10}\n",
    "                    ]\n",
    "cities = db.wau_county.aggregate(aggregation_query)\n",
    "print('First 10 users in the list:')\n",
    "for city in cities:\n",
    "    print str(city[\"_id\"]) + \": \" + str(city[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts for the different cities in the list changed between earlier data analysis on the XML data and now. Reason for the different numbers is the data cleaning done when transferring the data from XML to JSON. \n",
    "\n",
    "Example: Waukesha \n",
    "- Before data cleaning: \n",
    "        - Waukesa: 1\n",
    "        - Waukesha: 31\n",
    "        - Waukesha, WI: 1\n",
    "        - waukesha: 1\n",
    "- After data cleaning:\n",
    "        - Waukesha: 34\n",
    "        \n",
    "However, what's strange when looking at the different cities in the data, is that the cities with the highest occurences in the data, eg. Milwaukee, do not even below to Waukesha county. To be sure that is not an issue of the investigations on my side, I doulbechecked all everything from the beginning again... selection on OpenStreetMap, list of post codes, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "---------- Places of Worship ------------\n",
      "- Information on the RELIGION of Places -\n",
      "-----------------------------------------\n",
      "Christian: 52\n",
      "Buddhist: 2\n",
      "Jain: 1\n",
      "Sikh: 1\n",
      "Jewish: 1\n",
      "Muslim: 1\n",
      "Scientologist: 1\n",
      "Hindu: 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = [{\"$match\" : {\"addinfo.religion\" : {\"$exists\":1} , \"addinfo.type\" : \"place of worship\"}},\n",
    "                     {\"$group\" : {\"_id\" : \"$addinfo.religion\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "places_of_worship = db.wau_county.aggregate(aggregation_query)\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print('---------- Places of Worship ------------')\n",
    "print('- Information on the RELIGION of Places -')\n",
    "print('-----------------------------------------')\n",
    "for place in places_of_worship:\n",
    "    print str(place[\"_id\"]).title() + \": \" + str(place[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above information is displaying all the different religions places which are mentioned in the data. By far, Christian's places are most frequent with 52 appearances in the data. In the next section we take a closer look at those Christian's places and what denomination they follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "--------------- Places of Worship -----------------\n",
      "- Information on the DENOMINATION of Christian's -\n",
      "---------------------------------------------------\n",
      "None: 19\n",
      "Lutheran: 13\n",
      "Catholic: 8\n",
      "Episcopal: 2\n",
      "Methodist: 1\n",
      "Mormon: 1\n",
      "Evangelical: 1\n",
      "Presbyterian: 1\n",
      "Nondenominational: 1\n",
      "Congregational: 1\n",
      "Wisconsin_Evangelical_Lutheran_Synod_(Wels): 1\n",
      "Baptist: 1\n",
      "Pentecostal: 1\n",
      "Greek_Orthodox: 1\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = [{\"$match\" : {\"addinfo.religion\" : \"christian\" , \"addinfo.type\" : \"place of worship\"}},\n",
    "                     {\"$group\" : {\"_id\" : \"$addinfo.denomination\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "places_of_worship = db.wau_county.aggregate(aggregation_query)\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print('--------------- Places of Worship -----------------')\n",
    "print('- Information on the DENOMINATION of Christian\\'s -')\n",
    "print('---------------------------------------------------')\n",
    "for place in places_of_worship:\n",
    "    print str(place[\"_id\"]).title() + \": \" + str(place[\"count\"])\n",
    "print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good portion of all Christian places, there is no information about the denomination provided. However, from the data we have, we can see that Lutheran and Catholic denomination are most popular. _Note: What we can see here as well is a good of example of bad data quality. One denomination records has a value \"Wisconsin_Evangelical\\_Lutheran\\_Synod\\_(Wels)\". That seems to be wrong._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Ideas about the Data set\n",
    "\n",
    "In this section I will do some more investigations on the data set and point out chances for improvement of the data as well as some more interesting facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "-------- Cuisine in Restaurants --------\n",
      "----------------------------------------\n",
      "None: 241\n",
      "American: 28\n",
      "Pizza: 27\n",
      "Sandwich: 16\n",
      "Italian: 16\n",
      "Chinese: 12\n",
      "Burger: 11\n",
      "Japanese: 7\n",
      "Mexican: 7\n",
      "American_New: 7\n",
      "Regional: 4\n",
      "Greek: 3\n",
      "German: 3\n",
      "Steak_House: 3\n",
      "New_Orleans: 2\n",
      "New_American: 2\n",
      "Bagel: 2\n",
      "Irish: 2\n",
      "Sandwich: 2\n",
      "Asian: 2\n",
      "Indian: 2\n",
      "Korean: 2\n",
      "Seafood: 2\n",
      "Diner: 2\n",
      "Vietnamese: 2\n",
      "Ethiopian: 2\n",
      "Sushi: 2\n",
      "Chili: 1\n",
      "New_American; European: 1\n",
      "Wrap: 1\n",
      "American;Mediterranean: 1\n",
      "Chinese: 1\n",
      "European: 1\n",
      "Fast_Food: 1\n",
      "Noodles: 1\n",
      "Everything: 1\n",
      "Brunch: 1\n",
      "Vietnamese,Asian: 1\n",
      "Ice_Cream: 1\n",
      "Irish: 1\n",
      "International: 1\n",
      "Sub: 1\n",
      "Turkish: 1\n",
      "Asian_Fusion: 1\n",
      "Deli: 1\n",
      "World: 1\n",
      "Cuban: 1\n",
      "American_New: 1\n",
      "Pancake: 1\n",
      "Thai: 1\n",
      "Burger,_Pizza: 1\n",
      "Gastropub: 1\n",
      "Sandwich; Thai: 1\n",
      "Seafood; Grill: 1\n",
      "Pizza,_Burgers,_And_Fish_Frys: 1\n",
      "Steak: 1\n",
      "Dutch: 1\n",
      "Bbq: 1\n",
      "Pasta: 1\n",
      "Brazilian: 1\n",
      "----------------------------------------\n",
      "Number of Restaurants in the data: 444\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = [{\"$match\" : {\"addinfo.type\" : {\"$exists\":1} , \"addinfo.type\" : \"restaurant\"}},\n",
    "                     {\"$group\" : {\"_id\" : \"$addinfo.cuisine\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "restaurants = db.wau_county.aggregate(aggregation_query)\n",
    "\n",
    "c=0\n",
    "print('----------------------------------------')\n",
    "print('-------- Cuisine in Restaurants --------')\n",
    "print('----------------------------------------')\n",
    "for restaurant in restaurants:\n",
    "    print str(restaurant[\"_id\"]).title() + \": \" + str(restaurant[\"count\"])\n",
    "    c = c+restaurant[\"count\"]\n",
    "print('----------------------------------------')\n",
    "\n",
    "print \"Number of Restaurants in the data: \" + str(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What needs to be improved?__\n",
    "What we can see here is that we got a good number of 372 restaurants on the map for Waukesha County area already. However, where we can see room for improvement is definitley the specification of the cuisine. Only a about 130 restaurants provide cuisine information, where about 240 do not do so. \n",
    "\n",
    "\n",
    "__How to improve?__\n",
    "What's easy, is to find out which restaurant do no have cusine information provided and to additionally add certain information like website, phone, name, operator to that report, to enable potential \"data cleaners\" to request the data from a certain source. Where the report (below a sample report is provided, it can be improved to further support the \"data cleaner\") itself is a simple job which can be done by a data analyst, the retrieving and cleaning of the data requires manual effort and therefore might be quite a challange. _One the sample Report below: Already the name of most restaurants tells a lot about what cuisines is offererd, at least about a portion of it. Eg. Cold Spoons Gelato, Cranky Al's Bakery and Pizza, Crisp Pizza Bar and Lounge, Depot Snack Shop, Chiang Mai Thai, Chipotle Bar and Grill, Pitch's BBQ,..._\n",
    "\n",
    "\n",
    "__What are the benefits?__\n",
    "As especially restaurants might be locations which are interesting targets for map users, improved information would help increadying user satisfaction of OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "---- SAMPLE REPORT FOR FILLING RESTAURANT INFO ----\n",
      "---------------------------------------------------\n",
      "Name: Robert's Frozen Custard\n",
      "ID: 471082814\n",
      "--------------------------------------------\n",
      "Name: Meritage\n",
      "ID: 475437538\n",
      "--------------------------------------------\n",
      "Name: Cold Spoons Gelato\n",
      "ID: 475442109\n",
      "--------------------------------------------\n",
      "Name: Cranky Al's Bakery and Pizza\n",
      "ID: 475446467\n",
      "--------------------------------------------\n",
      "Name: Fazoli's\n",
      "ID: 545357522\n",
      "--------------------------------------------\n",
      "Name: Perkins\n",
      "ID: 545367151\n",
      "--------------------------------------------\n",
      "Name: Panera\n",
      "Opening Hours: Mo-Sa 06:00-20:30; Su 07:00-19:00\n",
      "ID: 573374681\n",
      "--------------------------------------------\n",
      "Name: Café Lulu\n",
      "ID: 573538503\n",
      "--------------------------------------------\n",
      "Name: Benji's Deli\n",
      "ID: 573736642\n",
      "--------------------------------------------\n",
      "Name: Denny's\n",
      "ID: 585911973\n",
      "--------------------------------------------\n",
      "Name: Comet Café\n",
      "Opening Hours: Sa-Su 09:00-22:00; Mo-Fr 10:00-22:00\n",
      "ID: 599825969\n",
      "--------------------------------------------\n",
      "ID: 619003078\n",
      "--------------------------------------------\n",
      "ID: 619003085\n",
      "--------------------------------------------\n",
      "Name: Jerry's Old Town Inn\n",
      "ID: 668002394\n",
      "--------------------------------------------\n",
      "Name: Bub's Irish Pub\n",
      "ID: 668002633\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "restaurants_wo_cusine = db.wau_county.find({\"addinfo.type\"    :\"restaurant\", \n",
    "                                            \"addinfo.cuisine\" : {\"$exists\":0}\n",
    "                                           })\n",
    "\n",
    "all_attrs = {\"id\" : \"ID\",\n",
    "        \"name\" : \"Name\",\n",
    "        \"operator\" : \"Operator\",\n",
    "        \"phone\" : \"Phone\",\n",
    "        \"website\" : \"Website\",\n",
    "        \"opening_hours\" : \"Opening Hours\"\n",
    "       }\n",
    "\n",
    "# as this is only a sample report, the output lines are limited to 15\n",
    "c = 0\n",
    "c_max = 15\n",
    "\n",
    "print \"---------------------------------------------------\"\n",
    "print \"---- SAMPLE REPORT FOR FILLING RESTAURANT INFO ----\"\n",
    "print \"---------------------------------------------------\"\n",
    "\n",
    "for restaurant in restaurants_wo_cusine:\n",
    "    \n",
    "    # counter for sample report\n",
    "    c = c+1\n",
    "    if c > c_max:\n",
    "        break\n",
    "    \n",
    "    # write results\n",
    "    for attr in all_attrs.keys():\n",
    "        try:\n",
    "            print all_attrs[attr] + \": \" + restaurant[attr]\n",
    "        except:\n",
    "            pass\n",
    "    print '--------------------------------------------'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "------- Different Types of Ways --------\n",
      "----------------------------------------\n",
      "Highway: 62593\n",
      "Building: 11027\n",
      "Leisure: 2392\n",
      "Parking: 2177\n",
      "Natural: 1938\n",
      "School: 328\n",
      "Restaurant: 129\n",
      "Place Of Worship: 103\n",
      "Fast Food: 72\n",
      "Fuel: 55\n",
      "Shelter: 52\n",
      "Bank: 48\n",
      "Bar: 37\n",
      "Theatre: 26\n",
      "Toilets: 24\n",
      "Fire Station: 21\n",
      "Grave Yard: 20\n",
      "Hospital: 19\n",
      "Pharmacy: 18\n",
      "Cafe: 17\n",
      "Library: 16\n",
      "Clinic: 13\n",
      "Community Centre: 12\n",
      "Townhall: 12\n",
      "Post Office: 12\n",
      "Car Wash: 10\n",
      "College: 10\n",
      "Pub: 10\n",
      "Bicycle Rental: 10\n",
      "University: 8\n",
      "Social Facility: 7\n",
      "Dentist: 6\n",
      "Nightclub: 6\n",
      "Police: 6\n",
      "Events Venue: 6\n",
      "Bicycle Parking: 6\n",
      "Public Building: 6\n",
      "Cinema: 5\n",
      "Marketplace: 5\n",
      "Social Centre: 4\n",
      "Courthouse: 4\n",
      "Recycling: 4\n",
      "Prison: 4\n",
      "Boatyard: 3\n",
      "Motorcycle Parking: 3\n",
      "Dojo: 3\n",
      "Biergarten: 3\n",
      "Swimming Pool: 3\n",
      "Nursing Home: 3\n",
      "Car Sharing: 2\n",
      "Fountain: 2\n",
      "Ranger Station: 2\n",
      "Ice Cream: 2\n",
      "Studio: 2\n",
      "Healthcare: 2\n",
      "Veterinary: 2\n",
      "Parking Space: 2\n",
      "Boat Storage: 1\n",
      "Car Rental: 1\n",
      "Architect Office: 1\n",
      "Hospice: 1\n",
      "Arts Centre: 1\n",
      "Mortuary: 1\n",
      "Ferry Terminal: 1\n",
      "Vehicle Inspection: 1\n",
      "Storage: 1\n",
      "Picnic Shelter: 1\n",
      "Kindergarten: 1\n",
      "Casino: 1\n",
      "Childcare: 1\n",
      "Atm: 1\n",
      "Social Club: 1\n",
      "Doctors: 1\n",
      "Whirlpool: 1\n",
      "Stripclub: 1\n",
      "Gym: 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = [{\"$match\" : {\"addinfo.type\" : {\"$exists\":1}, \"type\" : \"way\" } },\n",
    "                     {\"$group\" : {\"_id\" :\"$addinfo.type\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "ways = db.wau_county.aggregate(aggregation_query)\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('------- Different Types of Ways --------')\n",
    "print('----------------------------------------')\n",
    "for way in ways:\n",
    "    print str(way[\"_id\"]).title() + \": \" + str(way[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What needs to be improved?__\n",
    "\n",
    "Above you can see a list of different types of ways inside the dataset. Obviously, ways are not only streets, roads, avenues, paths,... All different kind of amenities have entered the way tags information. Altough, as per the definition of Way objects in the OpenStreetMap Wiki, Way objects are not designed to store such data. See link to OpenStreetMap Wiki below.\n",
    "\n",
    "__How to improve?__\n",
    "\n",
    "Programmatic ways seem to be applicable to clean the data to a certain degree. By combining different pieces of information (the Way object information itself, related/referenced objects) required information to build up Node objects based on that information should be availalbe. Although, it's required to develop a broader conceptional design to fully understand the scope of such a conversion project. Quickly drafting my thoughts: It looks like lot's of information within <tag>'s can be used to build up the Node objects info like \"creation\", \"maininfo\", \"addinfo\" (based on how I classify objects in JSON), from the referenced objects it should be possible to gather information about \"geopos\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE OF WAY ELEMENT WHICH \n",
    "<way id=\"381049573\" version=\"1\" timestamp=\"2015-11-18T18:31:24Z\" changeset=\"35414977\" uid=\"1952296\" user=\"shuui\">\n",
    "    <nd ref=\"1008172080\"/> # SEE EXAMPLE BELOW FOR REFERENCE\n",
    "    <nd ref=\"3843184249\"/>\n",
    "    <nd ref=\"3843184250\"/>\n",
    "    <nd ref=\"1008172388\"/>\n",
    "    <nd ref=\"1008171880\"/>\n",
    "    <nd ref=\"3843184251\"/>\n",
    "    <nd ref=\"1008172049\"/>\n",
    "    <nd ref=\"1008172080\"/> # SEE EXAMPLE BELOW FOR REFERENCE\n",
    "    <tag k=\"addr:city\" v=\"Milwaukee\"/>\n",
    "    <tag k=\"addr:housenumber\" v=\"209\"/>\n",
    "    <tag k=\"addr:postcode\" v=\"53204\"/>\n",
    "    <tag k=\"addr:state\" v=\"WI\"/>\n",
    "    <tag k=\"addr:street\" v=\"South Water Street\"/>\n",
    "    <tag k=\"amenity\" v=\"architect_office\"/>\n",
    "    <tag k=\"building\" v=\"commercial\"/>\n",
    "    <tag k=\"building:levels\" v=\"1\"/>\n",
    "    <tag k=\"building:year_built\" v=\"2015\"/>\n",
    "    <tag k=\"name\" v=\"pra Plunkett Raysich Archetects, LLP\"/>\n",
    "    <tag k=\"phone\" v=\"+1.800.208.7078\"/>\n",
    "    <tag k=\"website\" v=\"http://prarch.com\"/>\n",
    "  </way>\n",
    "\n",
    "# EXAMPLE OF NODE REFERENCES BY WAY OBJECT\n",
    "<node id=\"1008172080\" lat=\"43.0292647\" lon=\"-87.9083026\" version=\"3\" timestamp=\"2015-11-18T18:31:24Z\" changeset=\"35414977\" uid=\"1952296\" user=\"shuui\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What are the benefits?__\n",
    "\n",
    "Cleaning up the way tags information might support to get to more standardized data and thereby makes it easier to search for data, describe/explain certain data objects, build reports on the data, build navigation/view layers based on the data, and so on.\n",
    "\n",
    "\n",
    "_Definition of a \"Way\" in OpenStreetMap:_ https://wiki.openstreetmap.org/wiki/Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "------- Different Types of Ways --------\n",
      "----------------------------------------\n",
      "Natural: 74\n",
      "Leisure: 46\n",
      "Building: 26\n",
      "Parking: 9\n",
      "Highway: 8\n",
      "University: 3\n",
      "School: 3\n",
      "Library: 2\n",
      "College: 2\n",
      "Community Centre: 2\n",
      "Restaurant: 2\n",
      "Place Of Worship: 1\n",
      "Fuel: 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = [{\"$match\" : {\"addinfo.type\" : {\"$exists\":1}, \"type\" : \"relation\" } },\n",
    "                     {\"$group\" : {\"_id\" :\"$addinfo.type\", \"count\" : {\"$sum\" : 1}}},\n",
    "                     {\"$sort\" : {\"count\":-1}}\n",
    "                    ]\n",
    "ways = db.wau_county.aggregate(aggregation_query)\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('------- Different Types of Ways --------')\n",
    "print('----------------------------------------')\n",
    "for way in ways:\n",
    "    print str(way[\"_id\"]).title() + \": \" + str(way[\"count\"])\n",
    "print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://wiki.openstreetmap.org/wiki/Relation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
